{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Deep Convolutional Generative Adversarial Network (cDCGAN)\n",
    "### Exploring Different Architectures\n",
    "\n",
    "## Author's Note\n",
    "\n",
    "In my previous cDCGAN assignment, I built a cDCGAN and trained it on both the CIFAR10 and my novel dataset (of cyberpunk, cartoon, and noir artwork) for 60 epochs. I embedded the conditional input into the discriminator by concatenating it with the network activations from the convolutional blocks, right before they are fed into the final linear layer. The results showed some visual differences between the different CIFAR10 classes, even if the generated images did not really resemble the real images. The generated images for the novel dataset however had a high degree of visual similarity and were virtually indiscernible as different classes, except for minute visual differences such as slight variations in color intensity. My conclusion was that the model may be experiencing mode collapse, and that the underlying data itself may have low inter-class variation in the first place, thus exacerbating the mode collapse effect.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment, I intend to expand on the previous cDCGAN assignment by exploring different conditional DCGAN architectures, increasing the number of training epochs, and applying quantitative metrics to analyze the model results. The motivation behind each task is listed as follows:\n",
    "\n",
    "- **Exploring Different cDCGAN Architectures.** Since neural networks often operate in a black box, it is common to experiment with different network architectures to test out which one outperforms the other. As networks that are both deep and convolutional have been shown to return the best performance when working with image-related tasks (citation?), the different architectures to be explored will most likely still be deep and convolutional, with a modification being made to either the label-embedding method, or adding an upsampling method to increase image quality.\n",
    "\n",
    "\n",
    "- **Increasing Number of Training Epochs.** Increasing the number of training epochs will almost always generate better images since the model goes through more iterations of backpropagation, and so the parameter weights are further along in the fine-tuning process. As I only trained the model for 60 epochs previously, I intend to train the new model for at least 100 epochs.\n",
    "\n",
    "\n",
    "- **Applying Quantitative Metrics on the Results.**. Manual inspection of the model output can be extremely subjective and often inconclusive. While quantitative metrics such as the Inception Score (IS) or Fréchet Inception Distance (FID) should not necessarily be taken as a direct measure of how \"good\" the model is, they still provide a relatively objective measure of comparison of model performance, and can at least reveal some quantitative insights on the model's diversity and ability to generate real images based on comparisons with the generated image distributions on one hand, and the real image distribution on the other.\n",
    "\n",
    "## Literature Review\n",
    "\n",
    "### Conditional GAN\n",
    "\n",
    "According to Mirza and Osindero (2014), \"Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some extra information $y$. $y$ could be any kind of auxiliary information,\n",
    "such as class labels or data from other modalities. We can perform the conditioning by feeding $y$ into both the discriminator and generator as additional input layer.\"\n",
    "\n",
    "Some motivations for including the class label within the input are (Brownlee, 2019):\n",
    "\n",
    "- To improve GAN performance by making use of additional information (class labels) that is correlated with the input images.\n",
    "\n",
    "- To generate targeted images.\n",
    "\n",
    "### Embedding Class Labels\n",
    "\n",
    "Given a conditional GAN model, there are a few ways that one can choose to embed the class label. The efficacy of each embedding method in utilizing the label information to generate fake images and discriminate real images from fake ones can then be evaluated by comparing the quality of fake conditional images generated using the different methods.\n",
    "\n",
    "#### cGAN vs cDCGAN\n",
    "\n",
    "In a vanilla conditional GAN network with linear layers, $y$ could be embedded into the input via simple concatenation. According to Brownlee (2019), one of the best practices in encoding and incorporating class labels into both the discriminator and generator models entails \"using an embedding layer followed by a fully connected layer with a linear activation that scales the embedding to the size of the image before concatenating it in the model as an additional channel or feature map\".\n",
    "\n",
    "In a conditional DCGAN network with convolutional layers, the encoding of class labels becomes a bit trickier since the images are not flattened into a single dimension before being fed into the network. Instead, the DCGAN network normally takes in an input of 3 dimensions, i.e. width x heights x number of channels. The image is then continuously convolved through multiple kernels in the network without ever having to be flattened until a final classification decision has to be made using a linear layer (e.g. sigmoid) at the output. \n",
    "\n",
    "#### Label-Embedding Methods\n",
    "\n",
    "The figure below illustrates the different network architectures tested out by Cao, Dulloor, and Prasetio (2017) while building a conditional GAN to generate faces. The networks differ in the type of layers used (convolutional vs fully-connected) and the label-embedding method. Since cDenseGAN#1 and cDenseGAN#2 consist of only fully-connected layers, I will instead focus on the cDCGAN networks. \n",
    "\n",
    "<img src='cGAN-archs.png' style='width:75%'>\n",
    "\n",
    "The label-embedding method for the cDCGAN networks, alongside their motivation and results were as follows:\n",
    "\n",
    "- **cDCGAN#1**. Labels fed only to the first layer of the generator and discriminator. This method would seem like the most intuitive and obvious way of attempting to concatenate labels to an image being fed into a deep convolutional network. The results showed decent image quality.\n",
    "\n",
    "\n",
    "- **cDCGAN#2**. Labels fed to every single layer of the generator and discriminator. The motivation behind this method was that \"given sufficient mixing of conditionals at every layer, the model will be able to better learn the joint distribution of images and labels and produce good quality images with the correct identities\" (Cao, Dulloor, & Prasetio, 2017). However, the generated images were of very poor quality, i.e. highly pixelated and off-colour. The authors attributed this to the fact that mixing labels in every layer of the network resulted in a very sparse tensor with a lot of zeros in each of the layers (since the labels are concatenated to the layers as one-hot-encoded tensors).\n",
    "\n",
    "\n",
    "- **cDCGAN#3**. Labels fed straight to the fully-connected layers of both the generator and the discriminator. The idea being that \"there is no good reason to inject conditionals at any of the convolutional layers since conditionals do not have any spatial aspect\" (Cao, Dulloor, & Prasetio, 2017). The results showed a significant improvement in generated image quality.\n",
    "\n",
    "\n",
    "<img src='cdcgan-outputs.png' style='width:75%'>\n",
    "\n",
    "The **cDCGAN#1** network aligns with Kang's (2017) method of embedding the class labels to the image by concatenating the labels to the first convolutional layer. This means the image was \"conditioned\" on the class before going through the main convolutional layers.\n",
    "\n",
    "<img src='kang-cdcgan.png' style='width:75%'>\n",
    "\n",
    "Wang, Dantcheva, and Bremond (2018) also utilized this architecture when generating faces based on attributes that should affect facial appearance, e.g. male/female, young/old, smile/no smile. \n",
    "\n",
    "<img src='wang-network.png' style='width:75%'>\n",
    "\n",
    "<img src='wang-results.png' style='width:75%'>\n",
    "\n",
    "<img src='wang-eval.png' style='width:75%'>\n",
    "\n",
    "Their results showed a higher Inception Score (IS) and lower Fréchet Inception Distance (FID) when the model is trained on a higher number of conditional attributes. Since a high IS represents high generated image diversity and a low FID signifies that the generated images have low amount of different with the real images from the original dataset, their results suggest that the more conditionals the model can use as information, the higher quality the generated images (as evaluated by IS and FID). As such, apart from the network architecture itself, there is also a consideration of the type and quantity of data that is being fed into the network.\n",
    "\n",
    "The **cDCGAN#3** network aligns with Desai's (2018) method of embedding the class labels to the image after the convolutional layers, but before the input is fed into the fully-connected layers of the network. That is, given a conventional deep CNN model structured as `INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC` (Karpathy & Johnson, 2017), the class labels will be concatenated after the `CONV` block but before the `FC` layers.\n",
    "\n",
    "#### Architectural Choice for this Assignment\n",
    "\n",
    "In my previous assignment, I implemented Desai's (2018) method, aka **cDCGAN#3**, as I liked his reasoning that the class label should be considered a \"higher-level\" feature that would be embedded near the tail-end of the conditional DCGAN to provide further information to the network. Indeed, Cao, Dulloor, and Prasetio's (2017) empirical results also show that this architecture produces the best images, as evaluated both qualitatively (manual inspection) and quantitatively (since the images were celebrity faces, face-detection and ID-matching software were used to calculate quantitative results).\n",
    "\n",
    "In this assignment, I plan to implement Kang's (2017) method, aka **cDCGAN#1**, to compare the results against those of my previous assignment. While Cao, Dulloor, and Prasetio (2017) have already shown **cDCGAN#3** to be the superior architecture, it is still worth investigating the difference in generated image quality between **cDCGAN#1** and **cDCGAN#3** for myself since I am working with a novel dataset (cyberpunk, noir, and cartoon artwork). I can then compare the genre-conditioned artwork generated by each network to each other to evaluate the efficacy of the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "\n",
    "\n",
    "## Future Work\n",
    "\n",
    "- ArtGAN (Tan, Chan, Aguirre, & Tanaka, 2018)\n",
    "\n",
    "\n",
    "\n",
    "- Now I'm wondering if I should manually go through all my pics and label them with other categorical labels myself (dark, bright, character, place, etc.), or potentially automate that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b210150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameter Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = 'images'\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
    "image_size = 32\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 32\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(dataloader, classes, image_number = 8, model = None):\n",
    "    \n",
    "    '''\n",
    "    Function to plot a sample of images from the dataloader, alongside their class labels.\n",
    "    If a model is assigned to the model parameter, the predicted labels will be printed as well.\n",
    "    \n",
    "    Input:\n",
    "        dataloader (DATALOADER)\n",
    "            Dataloader of dataset.\n",
    "            \n",
    "        classes (ARR)\n",
    "            Array type object containing the class labels (strings) in the order that \n",
    "            corresponds with the numerical key in the dataloader.\n",
    "        \n",
    "        image_number (INT)\n",
    "            Number of images to plot from the dataloader. image_number should not exceed batch size.\n",
    "            Since images are plotted in a row, any number > 10 could cause display issues.\n",
    "            Default: 8.\n",
    "        \n",
    "        model (PYTORCH MODEL)\n",
    "            Optional parameter. If a model is provided, the predicted labels from the \n",
    "            model for each of the images will be printed as well. \n",
    "            Default: None.\n",
    "    '''\n",
    "    \n",
    "    # get images and true labels\n",
    "    images, labels = next(iter(dataloader))\n",
    "\n",
    "    # plot images\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(images.to(device)[:image_number], padding=1, normalize=True).cpu(),(1,2,0)))\n",
    "    \n",
    "    # print true labels\n",
    "    print('True labels: ', '     '.join('%5s' % classes[labels[j]] for j in range(image_number)))\n",
    "    \n",
    "    if model:\n",
    "        # predict image classes using custom net\n",
    "        outputs = model(images)\n",
    "        # the outputs are energies for the 10 classes. \n",
    "        # the higher the energy for a class, the more the network thinks that the image is of the particular class.\n",
    "        # So, we get the index of the highest energy:\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # print predicted labels\n",
    "        print('Predicted:  ', '   '.join('%5s' % classes[predicted[j]] for j in range(image_number)))\n",
    "\n",
    "\n",
    "def get_target_index(dataset):\n",
    "    '''\n",
    "    Given a dataset, this function returns a dictionary of classes, where the value of each class \n",
    "    is a dictionary containing the class indices and the number of datapoints in the class.\n",
    "    \n",
    "    Input:\n",
    "        dataset (IMAGEFOLDER)\n",
    "            Dataset should be ImageFolder class.\n",
    "        \n",
    "    Output:\n",
    "        idx_dct (DCT)\n",
    "            Nested dictionary with the class name as key, and a dictionary containing the\n",
    "            'indices' and 'length' of the class as values.\n",
    "            Example format:\n",
    "            idx_dct = { 'class_A':{\n",
    "                        'indices': [1,2,3,4,5],\n",
    "                        'length': 5\n",
    "                        },\n",
    "                        'class_B':{\n",
    "                        'indices': [6,7,8],\n",
    "                        'length': 3\n",
    "                        },\n",
    "                        'class_C':{\n",
    "                        'indices': [100,101,102,103],\n",
    "                        'length': 4\n",
    "                        }}\n",
    "    '''\n",
    "    targets = torch.tensor([t[1] for t in dataset.samples])\n",
    "    idx_dct = {}\n",
    "    \n",
    "    for k,v in dataset.class_to_idx.items():\n",
    "        idx_dct[k] = {'indices': (targets == v).nonzero().reshape(-1)}\n",
    "        idx_dct[k]['length'] = len(idx_dct[k]['indices'])\n",
    "        \n",
    "    return idx_dct\n",
    "\n",
    "\n",
    "def plot_batch(dataloader):    \n",
    "    '''\n",
    "    Plot images from a dataloader\n",
    "    '''\n",
    "    real_batch = next(iter(dataloader))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "True labels:   deer      deer       cat      deer      deer     horse       dog      frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transform images to tensor and normalize\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# create dataloaders\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "cifar_classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# plot sample of images\n",
    "plot_images(trainloader, cifar_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novel Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5def0d737fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                            \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                            \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                            ]))\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[1;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                           target_transform=target_transform)\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images'"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                           transforms.Resize(image_size),\n",
    "                           transforms.CenterCrop(image_size),\n",
    "                           transforms.RandomHorizontalFlip(p=0.5),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "target_idx_dct = get_target_index(dataset)\n",
    "for k,v in target_idx_dct.items():\n",
    "    print(f\"Class {k} has {v['length']} entries.\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "plot_images(dataloader, dataset.classes, image_number = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cDCGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    '''\n",
    "    Custom weights initialization called on netG and netD\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDiscriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, ngpu):\n",
    "        \n",
    "        super(cDiscriminator, self).__init__()\n",
    "        \n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.label_embedding = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        self.convolution_layers = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            # nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            # nn.BatchNorm2d(ndf * 8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(in_features = 1 + n_classes, # flattened output from last conv + embedding\n",
    "                      out_features = 512), # arbitrary + based on external references\n",
    "            \n",
    "            nn.LeakyReLU(0.2, inplace=True) ,\n",
    "        \n",
    "            nn.Linear(in_features = 512, # output from last linear layer\n",
    "                      out_features = 1), # true or false image\n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input, labels):\n",
    "        \n",
    "        x = self.convolution_layers(input) # run input through convolutional layers\n",
    "        # print(x.shape) # output shape: (128,1,1,1)\n",
    "        x = x.view(x.size(0), -1) # flatten output from main\n",
    "        # print(x.shape) # output shape: (128,1)\n",
    "        y = self.label_embedding(labels) # create label layer\n",
    "        # print(y.shape) # output shape: (128,3)\n",
    "        x = torch.cat((x, y), -1) # concatenate flattened output to label layer\n",
    "        # print(x.shape) # output shape: (128,4)\n",
    "        x = self.linear_layers(x) # run flattened + merged layer through linear layers\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class cGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, ngpu):\n",
    "        \n",
    "        super(cGenerator, self).__init__()\n",
    "        \n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            # input is Z + n_classes, going into a convolution\n",
    "            nn.ConvTranspose2d(nz + n_classes, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            # nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            # nn.BatchNorm2d(ngf),\n",
    "            # nn.ReLU(True),\n",
    "            \n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input, labels):\n",
    "    \n",
    "        # Concatenate label embedding and noise to produce input\n",
    "        flat_embed_input = torch.cat((self.label_emb(labels), input), -1)\n",
    "\n",
    "        # reshape flattened layer to torch.Size([128, nz+n_classes, 1, 1])\n",
    "        reshaped_input = flat_embed_input.view((-1,nz + self.n_classes,1,1)) \n",
    "        \n",
    "        gen_img = self.main(reshaped_input)\n",
    "        \n",
    "        return gen_img\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(object):\n",
    "    \n",
    "    '''\n",
    "    Conditional DCGAN class.\n",
    "    '''\n",
    "    \n",
    "    def _checkDirectory(self, dirName):\n",
    "        \n",
    "        if not os.path.exists(dirName):\n",
    "            print(f\"{dirName} directory does not exist. Making {dirName}\")\n",
    "            os.makedirs(dirName)\n",
    "            \n",
    "        else: print(f\"{dirName} directory exists.\")\n",
    "    \n",
    "    \n",
    "    def __init__(self, dataloader, classes, save_dir, num_epochs,\n",
    "                 criterion, netD, netG, optimizerD, optimizerG, device):\n",
    "        \n",
    "        # data parameters\n",
    "        self.dataloader = dataloader\n",
    "        self.classes = classes # class labels\n",
    "        self.n_classes = len(classes) # number of classes\n",
    "        \n",
    "        # save file locations\n",
    "        self._checkDirectory(save_dir) # check whether save dir exists\n",
    "        self.checkpoint_dir = os.path.join(save_dir, 'checkpoints')\n",
    "        self._checkDirectory(self.checkpoint_dir) # create checkpoints dir\n",
    "        self.fake_image_dir = os.path.join(save_dir, 'fake_images')\n",
    "        self._checkDirectory(self.fake_image_dir) # create fake images dir\n",
    "        \n",
    "        # model parameters\n",
    "        self.num_epochs = num_epochs # number of epochs to train for\n",
    "        self.start_epoch = 1 # the starting epoch\n",
    "        self.criterion = criterion # loss function\n",
    "        self.real_label = 1 # Establish convention for real and fake labels during training\n",
    "        self.fake_label = 0\n",
    "\n",
    "        # networks init\n",
    "        self.netD = netD\n",
    "        self.netG = netG\n",
    "        self.optimizerD = optimizerD\n",
    "        self.optimizerG = optimizerG\n",
    "        \n",
    "        # device\n",
    "        self.device = device # specify device being used\n",
    "        \n",
    "        # Create fixed noise to visualize the progression of the generator\n",
    "        self.fixed_noise = torch.randn(64, nz, device=self.device) # torch.Size([64, 100])\n",
    "            \n",
    "        \n",
    "    def generate_fake_images(self, class_index_tensor, noise, image_name = 'random', save = True):\n",
    "        \n",
    "        '''\n",
    "        Generate a batch of fake images using current generator weights.\n",
    "        \n",
    "        Inputs\n",
    "        \n",
    "            class_index_tensor (LongTensor)\n",
    "                The class index to create fake images for. The number of fake images generated is equal\n",
    "                to the length of the tensor. So a tensor filled with 10 \"1\"s will generate 10 images for\n",
    "                the class that corresponds to \"1\".\n",
    "                \n",
    "            noise (Tensor)\n",
    "                Random noise that will be put through the generator weights to produce an image.\n",
    "        \n",
    "            image_name (STR)\n",
    "                Image name for the saved file.\n",
    "                If running this function in model training, image_name should contain a changing variable,\n",
    "                otherwise the files will just keep overwriting each other with the same name.\n",
    "                Default: 'random' (in case save = True but no image_name provided)\n",
    "            \n",
    "            save (BOOL)\n",
    "                If save is TRUE, the image file will be saved in the specified \"self.fake_image_dir\".\n",
    "                Otherwise, just return the image data for plotting.\n",
    "                Default: TRUE\n",
    "            \n",
    "        ''' \n",
    "        with torch.no_grad():\n",
    "            # create fake images for a the labels in class_index_tensor\n",
    "            fake = self.netG(noise, class_index_tensor).detach().cpu()\n",
    "        \n",
    "        if save: # save images in the fake_image_dir\n",
    "            save_image(fake.data, f'{self.fake_image_dir}/{image_name}.png',\n",
    "                       nrow=8, padding=2, normalize=True)\n",
    "        \n",
    "        return fake.data\n",
    "    \n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        '''\n",
    "        Training loop\n",
    "        '''\n",
    "        if self.num_epochs == 0:\n",
    "            print(f\"No epochs set for training. Exiting training loop.\")\n",
    "            return\n",
    "            \n",
    "        # Lists to keep track of progress\n",
    "        self.G_losses = [] # generator loss\n",
    "        self.D_losses = [] # discriminator loss\n",
    "        iters = 0\n",
    "\n",
    "        print(\"Starting Training Loop...\")\n",
    "        # For each epoch\n",
    "        for epoch in range(self.start_epoch, self.start_epoch + self.num_epochs):\n",
    "            # For each batch in the dataloader\n",
    "            for i, (imgs, class_labels) in enumerate(self.dataloader):\n",
    "\n",
    "                ############################\n",
    "                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "                ###########################\n",
    "\n",
    "                ## Train with all-real batch\n",
    "                ###########################\n",
    "                self.netD.zero_grad()\n",
    "\n",
    "                # Format batch\n",
    "                real_imgs = imgs.to(self.device)\n",
    "                b_size = real_imgs.size(0)\n",
    "\n",
    "                # Set ground truth labels as REAL\n",
    "                validity_label = torch.full((b_size,), self.real_label, device=device)\n",
    "\n",
    "                # Forward pass real batch through D\n",
    "                output = self.netD(real_imgs, class_labels).view(-1)\n",
    "\n",
    "                # Calculate loss on all-real batch\n",
    "                errD_real = self.criterion(output, validity_label)\n",
    "\n",
    "                # Calculate gradients for D in backward pass\n",
    "                errD_real.backward()\n",
    "                D_x = output.mean().item()\n",
    "\n",
    "\n",
    "                ## Train with all-fake batch\n",
    "                ###########################\n",
    "                # Generate batch of latent vectors\n",
    "                noise = torch.randn(b_size, nz, device=device) # torch.Size([128, 10])\n",
    "\n",
    "                # Generate batch of fake labels\n",
    "                gen_labels = torch.randint(self.n_classes, (b_size,)).type(torch.LongTensor) # torch.Size([128, 3])\n",
    "\n",
    "                # Generate fake image batch with G\n",
    "                fake = self.netG(noise, gen_labels)\n",
    "\n",
    "                # Update ground truth labels to FAKE\n",
    "                validity_label.fill_(self.fake_label)\n",
    "\n",
    "                # Classify all fake batch with D\n",
    "                output = self.netD(fake.detach(), gen_labels).view(-1)\n",
    "\n",
    "                # Calculate D's loss on the all-fake batch\n",
    "                errD_fake = self.criterion(output, validity_label)\n",
    "\n",
    "                # Calculate the gradients for this batch\n",
    "                errD_fake.backward()\n",
    "                D_G_z1 = output.mean().item()\n",
    "\n",
    "                # Add the gradients from the all-real and all-fake batches\n",
    "                errD = errD_real + errD_fake\n",
    "\n",
    "                # Update D\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                ############################\n",
    "                # (2) Update G network: maximize log(D(G(z)))\n",
    "                ###########################\n",
    "\n",
    "                self.netG.zero_grad()\n",
    "\n",
    "                validity_label.fill_(self.real_label)  # fake labels are real for generator cost\n",
    "                \n",
    "                # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "                output = self.netD(fake, gen_labels).view(-1)\n",
    "                \n",
    "                # Calculate G's loss based on this output\n",
    "                errG = self.criterion(output, validity_label)\n",
    "                \n",
    "                # Calculate gradients for G\n",
    "                errG.backward()\n",
    "                D_G_z2 = output.mean().item()\n",
    "                \n",
    "                # Update G\n",
    "                self.optimizerG.step()\n",
    "\n",
    "                # Output training stats\n",
    "                if i % 50 == 0:\n",
    "                    print(f'[{epoch}/{self.start_epoch + self.num_epochs - 1}][{i}/{len(self.dataloader)}]\\tLoss_D: {round(errD.item(),2)}\\tLoss_G: {round(errG.item(),2)}\\tD(x): {round(D_x,2)}\\tD(G(z)): {round(D_G_z1/D_G_z2,2)}')\n",
    "\n",
    "                # Save Losses for plotting later\n",
    "                self.G_losses.append(errG.item())\n",
    "                self.D_losses.append(errD.item())\n",
    "\n",
    "                # Check how the generator is doing by saving G's output on fixed_noise\n",
    "                # every 500 iterations, or on the last batch of the last epoch\n",
    "                if (iters % 500 == 0) or ((epoch == self.num_epochs-1) and (i == len(self.dataloader)-1)):\n",
    "                    \n",
    "                    print(\"Saving a batch of fake images.\")\n",
    "                    \n",
    "                    class_index = torch.arange(self.n_classes) # get class indices\n",
    "                    for i in class_index:\n",
    "                        class_index_tensor = torch.LongTensor(64).fill_(i) # repeat the same class index 10 times\n",
    "                        self.generate_fake_images(class_index_tensor, self.fixed_noise,\n",
    "                                                  image_name = f'{self.classes[i]}_e{epoch}', save = True)\n",
    "\n",
    "                iters += 1\n",
    "\n",
    "            # automatically save model for first epoch (testing) and every 5 epochs\n",
    "            if epoch == 1 or epoch % 5 == 0: self.save(epoch)\n",
    "\n",
    "        print(f\"Finished Training for {epoch} epochs.\")\n",
    "        self.save(epoch)\n",
    "        \n",
    "        \n",
    "    def save(self, epoch):\n",
    "        \n",
    "        # save the model checkpoint\n",
    "        filepath = f'{self.checkpoint_dir}/checkpoint_e{epoch}.pth.tar'\n",
    "        print(f\"=> Saving checkpoint: {filepath}\")\n",
    "\n",
    "        state = {\n",
    "            'D_losses': self.D_losses,\n",
    "            'G_losses': self.G_losses,\n",
    "            'epoch': epoch,\n",
    "            'netD_state_dict': self.netD.state_dict(),\n",
    "            'optimizerD': self.optimizerD.state_dict(),\n",
    "            'netG_state_dict': self.netG.state_dict(),\n",
    "            'optimizerG': self.optimizerG.state_dict(),\n",
    "        }\n",
    "\n",
    "        torch.save(state, filepath) \n",
    "\n",
    "        \n",
    "    def load(self, loadpath):\n",
    "        '''\n",
    "        When loading model checkpoint, just load the epoch and state dicts to continue training.\n",
    "        The D-loss and G-loss can be stored within their respective checkpoints\n",
    "        and referred to later when needed.\n",
    "        '''\n",
    "        if os.path.isfile(loadpath):\n",
    "            print(f\"=> loading checkpoint: {loadpath}\")\n",
    "            checkpoint = torch.load(loadpath)\n",
    "\n",
    "            self.start_epoch = checkpoint['epoch'] + 1\n",
    "            self.netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "            self.netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "            self.optimizerD.load_state_dict(checkpoint['optimizerD'])\n",
    "            self.optimizerG.load_state_dict(checkpoint['optimizerG'])\n",
    "\n",
    "            print(f\"=> loaded checkpoint: {loadpath}\")\n",
    "            print(f\"Last epoch was {checkpoint['epoch']}\")\n",
    "\n",
    "        else: \n",
    "            print(f\"=> No checkpoint found at: {loadpath}\")\n",
    "        \n",
    "        \n",
    "    def visualize_results(self):\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "        plt.plot(self.G_losses,label=\"G\")\n",
    "        plt.plot(self.D_losses,label=\"D\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = cDiscriminator(len(cifar_classes), ngpu).to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)\n",
    "\n",
    "# Create the generator\n",
    "netG = cGenerator(len(cifar_classes), ngpu).to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'dataloader': trainloader, # cifar dataloader\n",
    "    'classes': cifar_classes, # cifar classes\n",
    "    'save_dir':'cDCGAN-cifar',\n",
    "    'num_epochs': 40,\n",
    "    'criterion': nn.BCELoss(), # Initialize BCELoss function\n",
    "    'netD': netD,\n",
    "    'netG': netG,\n",
    "    'optimizerD': optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)),\n",
    "    'optimizerG': optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)),\n",
    "    'device': device\n",
    "}\n",
    "    \n",
    "cdcgan_cifar = cDCGAN(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcgan_cifar.load('cDCGAN-cifar/checkpoints/checkpoint_e60.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novel Dataset Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = cDiscriminator(len(dataset.classes), ngpu).to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)\n",
    "\n",
    "# Create the generator\n",
    "netG = cGenerator(len(dataset.classes), ngpu).to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'dataloader': dataloader, # novel data dataloader\n",
    "    'classes': dataset.classes, # novel dataset classes\n",
    "    'save_dir':'cDCGAN',\n",
    "    'num_epochs': 0,\n",
    "    'criterion': nn.BCELoss(), # Initialize BCELoss function\n",
    "    'netD': netD,\n",
    "    'netG': netG,\n",
    "    'optimizerD': optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999)),\n",
    "    'optimizerG': optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999)),\n",
    "    'device': device\n",
    "}\n",
    "    \n",
    "cdcgan = cDCGAN(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcgan.load('cDCGAN/checkpoints/checkpoint_e60.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Visualizing Results\n",
    "\n",
    "The following functions were used to visualize the generated images. The output is seen in the results section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gen_images(classes, model, no_of_images = 10):\n",
    "    '''\n",
    "    Plots the generated images for each class.\n",
    "    \n",
    "    Inputs\n",
    "        classes (ARR)\n",
    "            List of classes to be used as labels for generating fake images.\n",
    "        \n",
    "        model (MODEL)\n",
    "            Pytorch model to be used for generating fake images.\n",
    "        \n",
    "        no_of_images (INT)\n",
    "            Number of fake images to generated for each class.\n",
    "            Default: 10.\n",
    "    '''\n",
    "    noise = torch.randn(no_of_images, nz, device=device)\n",
    "\n",
    "    for c in range(len(classes)):\n",
    "        images = model.generate_fake_images(torch.LongTensor(no_of_images).fill_(c), noise = noise, save = False)\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Fake {classes[c]} (epoch = 60)', size=20)\n",
    "        plt.imshow(np.transpose(vutils.make_grid(images, nrow = no_of_images, normalize = True), (1,2,0)))\n",
    "\n",
    "\n",
    "def plot_progression(my_dir, class_name, fig_w, fig_h, nrows, ncols, info = False):\n",
    "    '''\n",
    "    Plot the cDCGAN's image generation progression throughout the training process.\n",
    "    \n",
    "    Inputs\n",
    "        my_dir (STR)\n",
    "            Directory of generator progression images. \n",
    "            Images should be labelled with digit numbers for sorting.\n",
    "            \n",
    "        class_name (STR)\n",
    "            Specific class label to be plotted.\n",
    "            \n",
    "        fig_w (INT)\n",
    "            Figure width.\n",
    "        \n",
    "        fig_h (INT)\n",
    "            Figure height.\n",
    "  \n",
    "        nrows (INT)\n",
    "            Number of rows in plot.\n",
    "            \n",
    "        ncols (INT)\n",
    "            Number of columns in plot.\n",
    "            \n",
    "        info (BOOL)\n",
    "            If true, displays the number of images to be plotted and the list of image names.\n",
    "            Default: False.\n",
    "    '''\n",
    "    dir_list = os.listdir(my_dir) # get list of images in directory\n",
    "    img_list = [i for i in dir_list if class_name in i] # get list of images in a specific class\n",
    "    img_list.sort(key = lambda f: int(''.join(filter(str.isdigit, f)))) # sort in ascending order\n",
    "    \n",
    "    if info:\n",
    "        print(f\"There are {len(img_list)} images to be plotted. Adjust params accordingly.\")\n",
    "        print(f\"Images: {img_list}\")\n",
    "    \n",
    "    plt.figure(figsize=(fig_w, fig_h))\n",
    "    gs1 = gridspec.GridSpec(nrows, ncols)\n",
    "    gs1.update(wspace=0, hspace=0.025) # set the spacing between axes. \n",
    "\n",
    "    # view generator progression\n",
    "    for i in range(len(img_list)):\n",
    "        ax = plt.subplot(gs1[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "        img = mpimg.imread(f\"{my_dir}/{img_list[i]}\")\n",
    "        plt.imshow(img)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Brownlee, J. (2019, July 12). How to Develop a Conditional GAN (cGAN) From Scratch. Retrieved November 25, 2019, from https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/.\n",
    "\n",
    "Cao, X., Dulloor, S. R., & Prasetio, M. C. (2017). Face Generation with Conditional Generative Adversarial Networks. Retrieved December 18, 2019, from https://pdfs.semanticscholar.org/b1ff/d13e8f68401a603eea9806bc37e396a3c77d.pdf?_ga=2.8567484.88196337.1576674592-226014993.1574169937\n",
    "\n",
    "Desai, U. (2018, June 8). Training a Conditional DC-GAN on CIFAR-10. Retrieved November 25, 2019, from https://medium.com/@utk.is.here/training-a-conditional-dc-gan-on-cifar-10-fce88395d610.\n",
    "\n",
    "Kang, H. (2017, August 22). znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN. Retrieved November 25, 2019, from https://github.com/znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN.\n",
    "\n",
    "Karpathy, A., & Johnson, J. (2017). CS231n: Convolutional Neural Networks for Visual Recognition-Transfer Learning. Retrieved November 13, 2019, from https://cs231n.github.io/transfer-learning/#tf.\n",
    "\n",
    "Mirza, M., & Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784. Retrieved from https://arxiv.org/pdf/1411.1784.pdf\n",
    "\n",
    "Tan, W. R., Chan, C. S., Aguirre, H. E., & Tanaka, K. (2018). Improved artgan for conditional synthesis of natural image and artwork. IEEE Transactions on Image Processing, 28(1), 394-409. Retrieved December 18, 2019, from https://ieeexplore-ieee-org.ccl.idm.oclc.org/document/8444471\n",
    "\n",
    "Wang, Y., Dantcheva, A., & Bremond, F. (2018, September). From attributes to faces: a conditional generative network for face generation. In 2018 International Conference of the Biometrics Special Interest Group (BIOSIG) (pp. 1-5). IEEE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
