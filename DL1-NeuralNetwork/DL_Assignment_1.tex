
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Deep Learning Assignment 1: Neural Network Fundamentals}
    \author{Huey Ning Lok}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle


    In this assignment, we will implement a neural network from scratch
either in Numpy or in PyTorch but without using any of PyTorch's
implementations for layers, optimizers, loss functions, callbacks etc -
all significant logic relating to the neural network should be written
by the student. We are only allowed to use PyTorch for Numpy-like
GPU-accelerated tensor manipulation, dataset-related data structures,
and optionally gradient calculations (autograd).

\subsubsection*{Requirements:}\label{requirements}

Implement a fully-connected (feed-forward) neural network from scratch
in your library of choice. The NN must include at least dense layers,
activations, and sigmoid/softmax in case of classification. You must
also write your own optimizer and loss function (for example, stochastic
gradient descent and binary cross-entropy for binary classification).
You may use PyTorch's built-in gradient calculator (autograd) or you may
write one yourself.\\

Finally, include runtime and results on a public dataset (MNIST?
CIFAR10?).\\

Please document your code and write a brief summary which includes any
interesting technical details and your results.

\subsubsection*{Extensions:}\label{extensions}

Implement one or more of the following, and include a comparison of the
model's performance with/without each component:

\begin{itemize}
\tightlist
\item
  Manually calculate the gradients of each layer, and perform back
  propagation manually.
\item
  More than 1 activation function - sigmoid, tanh, relu etc.
\item
  More than 1 optimizer - SGD, Momentum, RMSProp, Adam etc.
\item
  Regularization - L2/weight decay, dropout, possibly augmentations if
  image data etc.
\end{itemize}

\subsubsection*{Submission:}\label{submission}

Please put all your code, results, and discussion in a jupyter notebook,
and submit a pdf of the notebook for ease of grading. You may also make
a secondary submission of the notebook (\emph{.ipynb) or the code
(}.py), but this is optional and might not be looked at.

    \section*{Assignment Layout}\label{assignment-layout}

The assignment will consist of two main parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Conceptual breakdown of the fundamentals of neural network
  architecture and the training process. This will allow me to grasp the
  fundamentals needed to code a neural network from scratch.
\item
  Coding of the neural network using Pytorch.
\end{enumerate}

    \section{Conceptual Breakdown}\label{conceptual-breakdown}

The steps for training a neural network can be broken down as follows:

    \subsection{Initialize the network
parameters.}\label{initialize-the-network-parameters.}

\subsubsection{Fixed Parameters}\label{fixed-parameters}

The fixed parameters are the number of neurons in each layer, aka the
layer size. These are usually defined by the user and determined as
according to our dataset needs.

\paragraph{Input size and hidden layer
size}\label{input-size-and-hidden-layer-size}

The number of neurons in the input layer and hidden layer(s) can be
defined arbitrarily or according to common best practices. Increasing
the number of neurons (and number of layers) can increase the model
capacity, i.e. the space of representable functions, which allows the
modelling of more complex relations, but also makes the model prone to
overfitting (Kaparthy, 2019). It is a general rule of thumb that the
number of learnable parameters should not exceed the number of data
points. That being said, Kaparthy argues that neural networks that are
overfitting can and should be adjusted using regularization methods vs
reducing the neuron count (2019).

Given the layer size(s) \(s\), we can calculate the number of learnable
parameters, \(p\), from a fully-connected network with \(N\) number of
layers as follows:

\(p_{\text{weights}} = \sum_{i=0}^{N}{s_{i}\cdot s_{i+1}}\)

\(p_{\text{bias}} = \sum_{i=1}^{N}{s_i}\)

\(p = p_{\text{weights}} + p_{\text{bias}}\)

In the equations above, \(i=0\) denotes the input layer and \(i=N\)
denotes the output layer.

\paragraph{Output size}\label{output-size}

In cases of binary classification or regression, the final output size
should be one. In multilabel classification, the final output size
should correspond to the number of classes.

\subsubsection{Learnable Parameters}\label{learnable-parameters}

While fixed parameters are only initialized once when defining the
network, learnable parameters are continuously updated throughout the
training process to minimize training loss and adjust the model's
predicted outputs to be closer to the actual output.

The learnable parameters consist of the model weights and biases, and
are usually randomly initialized.

\paragraph{Weights}\label{weights}

The weights determine the relationship between the neurons in a given
layer to the neurons in the layer before and after it. The heavier the
weight, the stronger the interneuron connection, and the stronger the
implication that the neuron significantly affects our model's prediction
ability. This is mostly relevant in regards to the input layer where the
neurons may represent clear features of a given dataset. Neurons in the
hidden layers are often less interpretable since they have undergone
multiple transformations, though there have been relatively successful
attempts at visualizing hidden layer features as shown in Olah,
Mordvintsev, and Schubert (2017).

\paragraph{Bias}\label{bias}

The bias term allows us to adjust the displacement of the output
functions of any given layer to achieve a better fit that reduces loss,
i.e. the difference between predicted \(\hat{y}\) and actual \(y\).

    \subsection{Perform a feed-forward pass to compute the predicted
output.}\label{perform-a-feed-forward-pass-to-compute-the-predicted-output.}

According to Karpathy (2016), "{[}t{]}he forward pass of a
fully-connected layer corresponds to one matrix multiplication followed
by a bias offset and an activation function". The forward pass allows us
to use the parameters that we have been training to predict an output
based on our input. The steps are as follows:

For each layer in the network:

\subsubsection{Multiply the layer inputs by their corresponding
weights and add the bias
offset.}\label{multiply-the-layer-inputs-by-their-corresponding-weights-and-add-the-bias-offset.}

Given a layer with weights \(\vec{w}\), inputs \(\vec{x}\), and bias
term \(b\), the output (before activation) can be calculated as follows:

\begin{align*}
o = \vec{w} \cdot \vec{x} + b
\end{align*}

\subsubsection{2.2 Apply an activation
function.}\label{apply-an-activation-function.}

Since the output is linear, we need to apply an activation function to
model non-linearity within our layer outputs. Given an activation
function \(g(x)\), our output can then be written as:

\begin{align*}
o = g(\vec{w} \cdot \vec{x} + b)
\end{align*}

Example activation functions include the sigmoid, softmax, rectified
linear units (ReLU), etc.

    \subsection{Compute the loss.}\label{compute-the-loss.}

The loss is defined as the difference between the predicted output
\(\hat{y}\) and the actual output \(y\) for an input \(\vec{x}\). The
loss is calculated using the loss function, which can take on different
forms as called for by the given problem.\\

For regression problems, we typically use the mean squared error (MSE)
as a loss function. For classification problems, we typically use
cross-entropy loss (also called log loss).

    \subsection{Update parameters using gradient descent and
backpropagation.}\label{update-parameters-using-gradient-descent-and-backpropagation.}

Given a MSE loss function
\(L(X) = \frac{1}{n}\sum_{i=1}^{n}{(\hat{y_i} - y_i)^2}\), where \(X\)
denotes a set of input-output pairs
\(X=\{(\vec{x_1},y_1),...,(\vec{x_n},y_n)\}\), \(\hat{y}\) denotes the
predicted output, and \({y}\) denotes the actual output, we see that
when \(\hat{y} = y\), \(L(X) = 0\). As such, a natural objective is to
minimize the loss function to achieve more accurate output. This can be
done by adjusting the parameters that will affect the output, as shown
in section 2.2.

\subsubsection{Calculating loss function gradient w.r.t. the
parameters using
backpropagation.}\label{calculating-loss-function-gradient-w.r.t.-the-parameters-using-backpropagation.}

The backpropagation algorithm uses the chain rule to calculate the
gradient of the loss function w.r.t. to the parameters, i.e. the weights
and biases. Given the final output of our neural network, \(y\), and
error \(E\), we can calculate the gradient of the error w.r.t. the
output as \(dE/dy\). We then find the gradient of error w.r.t input,
\(dE/dx = dE/dy * dy/dx\), where \(dy/dx\) is the derivative of the
activation function w.r.t. the output. After calculating \(dE/dx\) for
each layer, we can then use this in our calculation of the error
gradient w.r.t. the weights of each layer, \(dE/dw\). We then use this
error gradient to update our weights through gradient descent.

\subsubsection{Minimizing loss and updating parameters using
gradient
descent.}\label{minimizing-loss-and-updating-parameters-using-gradient-descent.}

Since we are trying to minimize the loss, this is an optimization
problem that can be solved using gradient descent. We typically use
stochastic gradient descent (SGD) whereby a parameter update is
performed for each training example \(x_i\) and training label \(y_i\)
(Ruder, 2018). Each iteration of gradient descent would be carried out
as follows:
\begin{align*}
\theta_{t+1} = \theta_t - \alpha \cdot \nabla_\theta L( \theta; x^{(i)}; y^{(i)})
\end{align*}

where \(\alpha\) represents the learning rate (usually user-defined and
should follow industry best practices) and
\(\nabla_\theta L( \theta; x^{(i)}; y^{(i)})\) represents the gradient
of the loss function w.r.t the parameters.\\

As seen from the update equation, each gradient descent step will update
our parameters in the direction that decreases loss. If the loss term
\((\alpha \cdot \nabla_\theta L( \theta; x^{(i)}; y^{(i)})\) is
positive, then the parameter values are decreased, i.e. we want to
decrease the significance of this parameter since it is increasing loss.
If the loss term is negative, then the parameter values are increased,
i.e. we want to increase the significance of this parameter since it is
decreasing loss.\\

Through gradient descent, we iteratively update our parameters to
achieve a local optima where loss is minimized.

\newpage
    \section{Coding the Neural Network}\label{coding-the-neural-network}

The following Pytorch functionalities were implemented:

\begin{itemize}
\tightlist
\item
  torch.tensor() \# to create tensors
\item
  torch.randn() \# to create tensors with random input
\item
  torch.matmul() \# to perform matrix multiplication
\item
  torch.t() \# to transpose matrices
\item
  math operations: torch.exp(), torch.mean()
\end{itemize}

The autograd functionality was not utilized, so backpropagation was
calculated manually.

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{c+c1}{\PYZsh{} import libraries}
        \PY{k+kn}{import} \PY{n+nn}{torch}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        \PY{n}{sns}\PY{o}{.}\PY{n}{set}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \subsection{Neural Network Class}\label{neural-network-class}

The neural network class consists of a forward method to calculate the
output, backward method to backpropagate and calculate the loss
gradients w.r.t. the weights, optimize method to perform gradient
descent and update the weights using the loss gradients, and finally a
train method which performs the forward, backward, and optimize methods
in order.\footnote{Link to the code gist can be found in the Appendix}\\

The neural network class takes the following input parameters:

\begin{itemize}
\tightlist
\item
  the layer architecture (number of layers, size of layers, etc.)
\item
  loss function
\item
  activation function
\item
  derivative of the activation function
\item
  learning rate (\(\alpha\))
\end{itemize}

I have defined the loss functions and activation functions (and their
derivatives) in separate cells.

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{c+c1}{\PYZsh{} define neural network class}
        
        \PY{k}{class} \PY{n+nc}{NeuralNetwork}\PY{p}{:}
        
          \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{layers}\PY{p}{,} \PY{n}{loss\PYZus{}func}\PY{p}{,} \PY{n}{active\PYZus{}func}\PY{p}{,} \PY{n}{active\PYZus{}func\PYZus{}prime}\PY{p}{,} \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.01}\PY{p}{)}\PY{p}{:}
        
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    Basic neural network class that can be trained on a given set of data using the}
        \PY{l+s+sd}{self.train method.}
        
        \PY{l+s+sd}{    Inputs:}
        
        \PY{l+s+sd}{      layers (ARR)}
        
        \PY{l+s+sd}{        \PYZhy{} Defines the architecture of the neural network.}
        \PY{l+s+sd}{        \PYZhy{} The array should contain sub\PYZhy{}arrays that represent the network layers, so that}
        \PY{l+s+sd}{          number of sub\PYZhy{}arrays == number of layers in network (including input and}
        \PY{l+s+sd}{output layers).}
        \PY{l+s+sd}{          Ex: [[...],[...],[...]] would represent a network with 3 layers.}
        \PY{l+s+sd}{        \PYZhy{} The sub\PYZhy{}arrays should each contain 2 numbers, the first representing the}
        \PY{l+s+sd}{number of input neurons}
        \PY{l+s+sd}{          and the second representing the number of output neurons.}
        \PY{l+s+sd}{          Ex: [5,3] would represent a layer with 5 input neurons and 3 output neurons.}
        \PY{l+s+sd}{          The following layer must accordingly have 3 input neurons, e.g. [3, x]}
        
        \PY{l+s+sd}{      loss\PYZus{}func (FUNC)}
        
        \PY{l+s+sd}{        \PYZhy{} Defines the loss function to be used in the neural network.}
        
        \PY{l+s+sd}{      active\PYZus{}func (FUNC)}
        
        \PY{l+s+sd}{        \PYZhy{} Defines the activation function to be used in the neural network.}
        \PY{l+s+sd}{        \PYZhy{} Only one type of activation function can be chosen, and this activation}
        \PY{l+s+sd}{function}
        \PY{l+s+sd}{          will be applied to each layer in the network, except the output layer.}
        
        \PY{l+s+sd}{      active\PYZus{}func\PYZus{}prime (FUNC)}
        
        \PY{l+s+sd}{        \PYZhy{} The derivative of the chosen activation function.}
        
        \PY{l+s+sd}{      alpha (FLOAT)}
        
        \PY{l+s+sd}{        \PYZhy{} Defines the learning rate to be used in the optimization method (SGD).}
        \PY{l+s+sd}{        \PYZhy{} Default: 0.01}
        
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
        
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}} \PY{c+c1}{\PYZsh{} empty dict to store layer weights}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}output\PYZus{}dct} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}} \PY{c+c1}{\PYZsh{} empty dict to store layer outputs}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{delta\PYZus{}dct} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}} \PY{c+c1}{\PYZsh{} empty dict to store loss gradients}
        
            \PY{k}{for} \PY{n}{l} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{layers}\PY{p}{)}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} randomly initialize layer weights according to layer size}
              \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{[}\PY{n}{l}\PY{p}{]} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{randn}\PY{p}{(}\PY{n}{layers}\PY{p}{[}\PY{n}{l}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{layers}\PY{p}{[}\PY{n}{l}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss\PYZus{}func} \PY{o}{=} \PY{n}{loss\PYZus{}func} \PY{c+c1}{\PYZsh{} type of loss function}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{active\PYZus{}func} \PY{o}{=} \PY{n}{active\PYZus{}func} \PY{c+c1}{\PYZsh{} type of activation function}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{active\PYZus{}func\PYZus{}prime} \PY{o}{=} \PY{n}{active\PYZus{}func\PYZus{}prime} \PY{c+c1}{\PYZsh{} derivative of activation function}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{alpha} \PY{o}{=} \PY{n}{alpha} \PY{c+c1}{\PYZsh{} learning rate}
        
        
          \PY{k}{def} \PY{n+nf}{forward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{layer\PYZus{}input}\PY{p}{)}\PY{p}{:}
        
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    *** Forward\PYZhy{}pass algorithm ***}
        \PY{l+s+sd}{    Multiplies the layer inputs by layer weights and applies the user\PYZhy{}defined activation}
        \PY{l+s+sd}{function to every layer except the final output layer.}
        
        \PY{l+s+sd}{    Inputs:}
        
        \PY{l+s+sd}{      layer\PYZus{}input (ARR)}
        \PY{l+s+sd}{        The layer inputs.}
        
        \PY{l+s+sd}{    Outputs:}
        
        \PY{l+s+sd}{      layer\PYZus{}output (ARR)}
        \PY{l+s+sd}{        The output of the final layer.}
        
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
        
            \PY{n}{layer\PYZus{}output} \PY{o}{=} \PY{l+m+mi}{0} \PY{c+c1}{\PYZsh{} initialize output value as 0}
        
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{)}\PY{p}{)}\PY{p}{:} \PY{c+c1}{\PYZsh{} loop through each layer in the network}
        
              \PY{n}{layer\PYZus{}output} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{layer\PYZus{}input}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} multiply the layer input by its weights}
        
              \PY{k}{if} \PY{n}{i} \PY{o}{!=} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{:} \PY{c+c1}{\PYZsh{} apply activation function to all layers but the last}

                \PY{n}{layer\PYZus{}output} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{active\PYZus{}func}\PY{p}{(}\PY{n}{layer\PYZus{}output}\PY{p}{)} \PY{c+c1}{\PYZsh{} activation function}
        
              \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}output\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{layer\PYZus{}output} \PY{c+c1}{\PYZsh{} add layer output to the layer output dict}

              \PY{n}{layer\PYZus{}input} \PY{o}{=} \PY{n}{layer\PYZus{}output} \PY{c+c1}{\PYZsh{} pass the output as the input to the next layer}
        
            \PY{k}{return} \PY{n}{layer\PYZus{}output} \PY{c+c1}{\PYZsh{} return final output of last layer in the network}
        
        
          \PY{k}{def} \PY{n+nf}{backward}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{output}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)}\PY{p}{:}
        
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    *** Backpropagation algorithm ***}
        \PY{l+s+sd}{    Loops through the network in reverse to calculate and sstore the}
        \PY{l+s+sd}{    error derivative w.r.t. the total input of a node, dE/dx.}
        \PY{l+s+sd}{    The dE/dx\PYZsq{}s are stored in delta\PYZus{}dct.}
        
        \PY{l+s+sd}{    Inputs:}
        
        \PY{l+s+sd}{      output (ARR)}
        \PY{l+s+sd}{        The predicted y values, i.e. final layer outputs.}
        
        \PY{l+s+sd}{      y\PYZus{}true (ARR)}
        \PY{l+s+sd}{        The true y values.}
        
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
        
            \PY{n}{err} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{loss\PYZus{}func}\PY{p}{(}\PY{n}{output}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)} \PY{c+c1}{\PYZsh{} output error, dE/dy}

            \PY{c+c1}{\PYZsh{} derivative of error w.r.t input, dE/dx = dE/dy * dy/dx,}
 	   \PY{c+c1}{\PYZsh{} where dy/dx is the derivative of the activation function w.r.t. the output}
            \PY{n}{delta} \PY{o}{=} \PY{n}{err} \PY{o}{*} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{active\PYZus{}func\PYZus{}prime}\PY{p}{(}\PY{n}{output}\PY{p}{)} 
        
        	   \PY{c+c1}{\PYZsh{} loop through the layers in reverse to backprop}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{reversed}\PY{p}{(}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{:} 

        
              \PY{n}{err} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{delta}\PY{p}{,} \PY{n}{torch}\PY{o}{.}\PY{n}{t}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} dE/dy for the layer}
              \PY{n}{delta} \PY{o}{=} \PY{n}{err} \PY{o}{*} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{active\PYZus{}func\PYZus{}prime}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}output\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} dE/dx for the layer}

        
              \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{delta\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{delta} \PY{c+c1}{\PYZsh{} save the deltas for calculating the loss gradient w.r.t. params, dE/dw}

        
        
          \PY{k}{def} \PY{n+nf}{optimize}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{layer\PYZus{}input}\PY{p}{)}\PY{p}{:}
        
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    *** Optimization step: Gradient Descent ***}
        \PY{l+s+sd}{    Loops through the network and calculates the the error derivative w.r.t. the weights}
        \PY{l+s+sd}{coming into the nodes of each layer, dE/dw. Ths loss gradient is then used to update the weights}
        \PY{l+s+sd}{by multiplying it with a learning\PYZus{}rate factor.}
        
        \PY{l+s+sd}{    Inputs:}
        
        \PY{l+s+sd}{      layer\PYZus{}input (ARR)}
        \PY{l+s+sd}{        The initial input of the first layer, aka the \PYZdq{}X\PYZdq{} data.}
        
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{c+c1}{\PYZsh{} loop through all layers except the output layer which doesn\PYZsq{}t have params to optimize}
     
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
        
              \PY{n}{loss\PYZus{}gradient} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{torch}\PY{o}{.}\PY{n}{t}\PY{p}{(}\PY{n}{layer\PYZus{}input}\PY{p}{)}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{delta\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{calculate dE/dw}}
              \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{weight\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{\PYZhy{}}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{alpha} \PY{o}{*} \PY{n}{loss\PYZus{}gradient} \PY{c+c1}{\PYZsh{} update params using α * dE/dw}
        
              \PY{c+c1}{\PYZsh{} the input for the next layer, i + 1, will be the output from the layer before it, i}
              \PY{n}{layer\PYZus{}input} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{layer\PYZus{}output\PYZus{}dct}\PY{p}{[}\PY{n}{i}\PY{p}{]}
        
        
          \PY{k}{def} \PY{n+nf}{train}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{layer\PYZus{}input}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)}\PY{p}{:}
        
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    *** Train the Network ***}
        \PY{l+s+sd}{    Trains the neural network through one iteration of:}
        \PY{l+s+sd}{    1) Calculating the predicted y\PYZsq{}s using a forward pass on the x data,}
        \PY{l+s+sd}{    2) Using backprop to find the loss gradients,}
        \PY{l+s+sd}{    3) Optimizing weights using the loss gradients.}
        
        \PY{l+s+sd}{    Inputs:}
        
        \PY{l+s+sd}{      layer\PYZus{}input (MAT)}
        \PY{l+s+sd}{        The initial input of the first layer, aka the \PYZdq{}X\PYZdq{} data.}
        
        \PY{l+s+sd}{      y\PYZus{}true (MAT)}
        \PY{l+s+sd}{        The true y values.}
        
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
        
            \PY{c+c1}{\PYZsh{} forward pass}
            \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{layer\PYZus{}input}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} backward pass}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{backward}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)}
            \PY{c+c1}{\PYZsh{} optimize}
            \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{optimize}\PY{p}{(}\PY{n}{layer\PYZus{}input}\PY{p}{)}
\end{Verbatim}

    \subsection{Activation Functions and their
Derivatives}\label{activation-functions-and-their-derivatives}

The activation functions defined are the sigmoid and rectified linear
units (ReLU) functions (and their derivatives).

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{sigmoid}\PY{p}{(}\PY{n}{s}\PY{p}{)}\PY{p}{:} \PY{c+c1}{\PYZsh{} for binary classification}
          \PY{k}{return} \PY{l+m+mi}{1}\PY{o}{/}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{n}{torch}\PY{o}{.}\PY{n}{exp}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{s}\PY{p}{)}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{sigmoid\PYZus{}prime}\PY{p}{(}\PY{n}{s}\PY{p}{)}\PY{p}{:}
          \PY{k}{return} \PY{n}{s} \PY{o}{*} \PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{s}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{relu}\PY{p}{(}\PY{n}{s}\PY{p}{)}\PY{p}{:}
          \PY{k}{return} \PY{n}{s} \PY{o}{*} \PY{p}{(}\PY{n}{s} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{)}\PY{o}{.}\PY{n}{float}\PY{p}{(}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{relu\PYZus{}prime}\PY{p}{(}\PY{n}{s}\PY{p}{)}\PY{p}{:}
          \PY{k}{return} \PY{l+m+mf}{1.} \PY{o}{*} \PY{p}{(}\PY{n}{s} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{)}\PY{o}{.}\PY{n}{float}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \subsection{Loss Functions}\label{loss-functions}

The loss functions defined are the absolute error loss and square error
loss. Due to time constraints, I have chosen to train and my neural
network on a regression problem, and so did not include a
classification-appropriate loss function, e.g. cross-entropy.

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{absolute\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)}\PY{p}{:}
          \PY{k}{return} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{y\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}true}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{square\PYZus{}error}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}true}\PY{p}{)}\PY{p}{:}
          \PY{k}{return} \PY{p}{(}\PY{n}{y\PYZus{}pred} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}true}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}
\end{Verbatim}

\newpage
   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{k}{def} \PY{n+nf}{run\PYZus{}nn}\PY{p}{(}\PY{n}{NN}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{disp} \PY{o}{=} \PY{k+kc}{False}\PY{p}{)}\PY{p}{:}
        
          \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{  Basic training function to train the neural network over a set amount of epochs and}
        \PY{l+s+sd}{return the train and test loss.}
        
        
        \PY{l+s+sd}{  Inputs:}
        
        \PY{l+s+sd}{    NN (OBJ)}
        \PY{l+s+sd}{      The initialized neural network object.}
        
        \PY{l+s+sd}{    X\PYZus{}train (ARR)}
        \PY{l+s+sd}{      The training input.}
        
        \PY{l+s+sd}{    y\PYZus{}train (ARR)}
        \PY{l+s+sd}{      The true training output.}
        
        \PY{l+s+sd}{    X\PYZus{}test (ARR)}
        \PY{l+s+sd}{      The testing input.}
        
        \PY{l+s+sd}{    y\PYZus{}test (ARR)}
        \PY{l+s+sd}{      The true testing output.}
        
        \PY{l+s+sd}{    epochs (INT)}
        \PY{l+s+sd}{      Number of epochs to train the network.}
        \PY{l+s+sd}{      Default: 1000}
        
        \PY{l+s+sd}{    disp (BOOL)}
        \PY{l+s+sd}{      If true, prints the epoch, train loss, and test loss per 100 epochs.}
        \PY{l+s+sd}{      If false, does not print anything.}
        \PY{l+s+sd}{      Default: False}
        
        
        \PY{l+s+sd}{  Outputs:}
        
        \PY{l+s+sd}{    running\PYZus{}train\PYZus{}loss (ARR)}
        \PY{l+s+sd}{      The training loss at each epoch}
        
        \PY{l+s+sd}{    running\PYZus{}test\PYZus{}loss (ARR)}
        \PY{l+s+sd}{      The test loss at each epoch}
        
        \PY{l+s+sd}{  \PYZsq{}\PYZsq{}\PYZsq{}}
        
          \PY{c+c1}{\PYZsh{} keep track of train and test loss}
          \PY{n}{running\PYZus{}train\PYZus{}loss} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          \PY{n}{running\PYZus{}test\PYZus{}loss} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        
          \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{epochs}\PY{p}{)}\PY{p}{:}
        
            \PY{c+c1}{\PYZsh{} train network}
            \PY{n}{NN}\PY{o}{.}\PY{n}{train}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
            \PY{n}{train\PYZus{}loss} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{absolute\PYZus{}error}\PY{p}{(}\PY{n}{NN}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{)}
            \PY{n}{running\PYZus{}train\PYZus{}loss}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{train\PYZus{}loss}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} test network}
            \PY{n}{test\PYZus{}loss} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{absolute\PYZus{}error}\PY{p}{(}\PY{n}{NN}\PY{o}{.}\PY{n}{forward}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
            \PY{n}{running\PYZus{}test\PYZus{}loss}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{test\PYZus{}loss}\PY{p}{)}
        
            \PY{k}{if} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{l+m+mi}{100} \PY{o}{==} \PY{l+m+mi}{0} \PY{o+ow}{and} \PY{n}{disp} \PY{o}{==} \PY{k+kc}{True}\PY{p}{:}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Epoch }\PY{l+s+si}{\PYZob{}i\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
              \PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Train Loss: }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{train\PYZus{}loss}\PY{p}{)}\PY{p}{)}
              \PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Test Loss: }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{test\PYZus{}loss}\PY{p}{)}\PY{p}{)}
        
          \PY{k}{return} \PY{n}{running\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{running\PYZus{}test\PYZus{}loss}
\end{Verbatim}

    \subsection{Neural Network Test: Fake
Data}\label{neural-network-test-fake-data}

A fake dataset is generated to train and test the neural network class.

    \subsubsection{Create the Fake Data}\label{create-the-fake-data}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}269}]:} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{)}
          
          \PY{k}{def} \PY{n+nf}{f}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{torch}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{+} \PY{n}{torch}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{dim}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)} \PY{o}{+} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.05}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} train set}
          \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{randn}\PY{p}{(}\PY{l+m+mi}{500}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}
          \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{f}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} test set}
          \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{randn}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}
          \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{f}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\},fontsize=\footnotesize]
torch.Size([500, 5]) torch.Size([100, 5]) torch.Size([500, 1]) torch.Size([100, 1])

    \end{Verbatim}

    \subsubsection{Run the Neural Network}\label{run-the-neural-network}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{c+c1}{\PYZsh{} define layer sizes}
        \PY{n}{input\PYZus{}s} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{size}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{hidden\PYZus{}s} \PY{o}{=} \PY{l+m+mi}{10}
        \PY{n}{output\PYZus{}s} \PY{o}{=} \PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{} initialize networks}
        \PY{n}{MAE\PYZus{}NN} \PY{o}{=} \PY{n}{NeuralNetwork}\PY{p}{(}\PY{n}{layers} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{tensor}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{input\PYZus{}s}\PY{p}{,} \PY{n}{hidden\PYZus{}s}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{hidden\PYZus{}s}\PY{p}{,}
        \PY{n}{output\PYZus{}s}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                           \PY{n}{loss\PYZus{}func} \PY{o}{=} \PY{n}{absolute\PYZus{}error}\PY{p}{,}
                           \PY{n}{active\PYZus{}func} \PY{o}{=} \PY{n}{relu}\PY{p}{,}
                           \PY{n}{active\PYZus{}func\PYZus{}prime} \PY{o}{=} \PY{n}{relu\PYZus{}prime}\PY{p}{,}
                           \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.001}\PY{p}{)}
        
        \PY{n}{MSE\PYZus{}NN} \PY{o}{=} \PY{n}{NeuralNetwork}\PY{p}{(}\PY{n}{layers} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{tensor}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{input\PYZus{}s}\PY{p}{,} \PY{n}{hidden\PYZus{}s}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{hidden\PYZus{}s}\PY{p}{,}
        \PY{n}{output\PYZus{}s}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                           \PY{n}{loss\PYZus{}func} \PY{o}{=} \PY{n}{square\PYZus{}error}\PY{p}{,}
                           \PY{n}{active\PYZus{}func} \PY{o}{=} \PY{n}{relu}\PY{p}{,}
                           \PY{n}{active\PYZus{}func\PYZus{}prime} \PY{o}{=} \PY{n}{relu\PYZus{}prime}\PY{p}{,}
                           \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.001}\PY{p}{)}
        
        
        \PY{n}{MAE\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{MAE\PYZus{}test\PYZus{}loss} \PY{o}{=} \PY{n}{run\PYZus{}nn}\PY{p}{(}\PY{n}{MAE\PYZus{}NN}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{epochs}
        \PY{o}{=} \PY{l+m+mi}{1000}\PY{p}{)}
        \PY{n}{MSE\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{MSE\PYZus{}test\PYZus{}loss} \PY{o}{=} \PY{n}{run\PYZus{}nn}\PY{p}{(}\PY{n}{MSE\PYZus{}NN}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{epochs}
        \PY{o}{=} \PY{l+m+mi}{1000}\PY{p}{)}
\end{Verbatim}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}276}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
          
          \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{1000}
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Neural Network with MAE Loss Function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MAE\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MAE\PYZus{}test\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epochs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Neural Network with MSE Loss Function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MSE\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MSE\PYZus{}test\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epochs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}276}]:} <matplotlib.legend.Legend at 0x7fedc389d5c0>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{DL_Assignment_1_files/DL_Assignment_1_22_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The results show that the neural network is decreasing loss at a higher
rate when trained using the MAE loss function vs the MSE loss function.
The "jitter" in the loss lines suggest that the network is quite
unstable, i.e. it is unable to smoothly converge to the local optima and
is instead taking steps towards and away from it repeatedly.

    \subsection{Neural Network Test: Public
Dataset}\label{neural-network-test-public-dataset}

In this section, I train and test my neural network on a public dataset,
specifically the Boston Housing Prices dataset (Scikit-learn, 2019)
which takes in the following inputs:

\begin{itemize}
\tightlist
\item
  CRIM per capita crime rate by town
\item
  ZN proportion of residential land zoned for lots over 25,000 sq.ft.
\item
  INDUS proportion of non-retail business acres per town
\item
  CHAS Charles River dummy variable (= 1 if tract bounds river; 0
  otherwise)
\item
  NOX nitric oxides concentration (parts per 10 million)
\item
  RM average number of rooms per dwelling
\item
  AGE proportion of owner-occupied units built prior to 1940
\item
  DIS weighted distances to five Boston employment centres
\item
  RAD index of accessibility to radial highways
\item
  TAX full-value property-tax rate per \$10,000
\item
  PTRATIO pupil-teacher ratio by town
\item
  B 1000(Bk - 0.63)\^{}2 where Bk is the proportion of blacks by town
\item
  LSTAT \% lower status of the population
\end{itemize}

To return the following output:

\begin{itemize}
\tightlist
\item
  MEDV Median value of owner-occupied homes in \$1000's
\end{itemize}

    \subsubsection{Import Boston Housing Prices
Dataset}\label{import-boston-housing-prices-dataset}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}160}]:} \PY{c+c1}{\PYZsh{} load data}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k}{import} \PY{n}{load\PYZus{}boston}
          \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
          
          \PY{n}{boston} \PY{o}{=} \PY{n}{load\PYZus{}boston}\PY{p}{(}\PY{p}{)}
          
          \PY{n}{boston\PYZus{}data\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{boston}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n}{boston}\PY{o}{.}\PY{n}{feature\PYZus{}names}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{boston}\PY{o}{.}\PY{n}{data}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          \PY{n}{boston\PYZus{}data\PYZus{}df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\},fontsize=\footnotesize]
(506, 13)

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}160}]:}         CRIM     ZN  INDUS   CHAS    NOX  {\ldots}    RAD    TAX  PTRATIO      B  LSTAT
          count  506.0  506.0  506.0  506.0  506.0  {\ldots}  506.0  506.0    506.0  506.0  506.0
          mean     4.0   11.0   11.0    0.0    1.0  {\ldots}   10.0  408.0     18.0  357.0   13.0
          std      9.0   23.0    7.0    0.0    0.0  {\ldots}    9.0  169.0      2.0   91.0    7.0
          min      0.0    0.0    0.0    0.0    0.0  {\ldots}    1.0  187.0     13.0    0.0    2.0
          25\%      0.0    0.0    5.0    0.0    0.0  {\ldots}    4.0  279.0     17.0  375.0    7.0
          50\%      0.0    0.0   10.0    0.0    1.0  {\ldots}    5.0  330.0     19.0  391.0   11.0
          75\%      4.0   12.0   18.0    0.0    1.0  {\ldots}   24.0  666.0     20.0  396.0   17.0
          max     89.0  100.0   28.0    1.0    1.0  {\ldots}   24.0  711.0     22.0  397.0   38.0
          
          [8 rows x 13 columns]
\end{Verbatim}
            
   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}161}]:} \PY{n}{boston\PYZus{}target\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{boston}\PY{o}{.}\PY{n}{target}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{MEDIAN VALUE}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{boston}\PY{o}{.}\PY{n}{target}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          \PY{n}{boston\PYZus{}target\PYZus{}df}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\},fontsize=\footnotesize]
(506,)

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}161}]:}        MEDIAN VALUE
          count         506.0
          mean           23.0
          std             9.0
          min             5.0
          25\%            17.0
          50\%            21.0
          75\%            25.0
          max            50.0
\end{Verbatim}
            
    \subsubsection{Transform and Preprocess
Data}\label{transform-and-preprocess-data}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}277}]:} \PY{c+c1}{\PYZsh{} scale data}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k}{import} \PY{n}{StandardScaler}
          \PY{n}{scaler} \PY{o}{=} \PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}
          \PY{n}{X} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{boston}\PY{o}{.}\PY{n}{data}\PY{p}{)}
          \PY{n}{y} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{boston}\PY{o}{.}\PY{n}{target}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} split data into train and test}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
          \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.4}\PY{p}{,}
          \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\},fontsize=\footnotesize]
(303, 13) (203, 13) (303, 1) (203, 1)

    \end{Verbatim}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}279}]:} \PY{c+c1}{\PYZsh{} transform data into tensor with dtype = Float}
          \PY{k}{def} \PY{n+nf}{transform\PYZus{}to\PYZus{}tensor}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{torch}\PY{o}{.}\PY{n}{tensor}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n}{torch}\PY{o}{.}\PY{n}{float}\PY{p}{)}
          
          \PY{n}{X\PYZus{}train} \PY{o}{=} \PY{n}{transform\PYZus{}to\PYZus{}tensor}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
          \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{transform\PYZus{}to\PYZus{}tensor}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
          \PY{n}{y\PYZus{}train} \PY{o}{=} \PY{n}{transform\PYZus{}to\PYZus{}tensor}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}
          \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{transform\PYZus{}to\PYZus{}tensor}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\},fontsize=\footnotesize]
torch.Size([303, 13]) torch.Size([203, 13]) torch.Size([303, 1]) torch.Size([203, 1])
    \end{Verbatim}

    \subsubsection{Run the Neural Network}\label{run-the-neural-network}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}0}]:} \PY{c+c1}{\PYZsh{} define layer sizes}
        \PY{n}{input\PYZus{}s} \PY{o}{=} \PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{hidden\PYZus{}s} \PY{o}{=} \PY{l+m+mi}{30}
        \PY{n}{output\PYZus{}s} \PY{o}{=} \PY{l+m+mi}{1}
        
        \PY{c+c1}{\PYZsh{} initialize networks}
        \PY{n}{MAE\PYZus{}boston\PYZus{}NN} \PY{o}{=} \PY{n}{NeuralNetwork}\PY{p}{(}\PY{n}{layers} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{tensor}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{input\PYZus{}s}\PY{p}{,} \PY{n}{hidden\PYZus{}s}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{hidden\PYZus{}s}\PY{p}{,}
        \PY{n}{output\PYZus{}s}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                           \PY{n}{loss\PYZus{}func} \PY{o}{=} \PY{n}{absolute\PYZus{}error}\PY{p}{,}
                           \PY{n}{active\PYZus{}func} \PY{o}{=} \PY{n}{sigmoid}\PY{p}{,}
                           \PY{n}{active\PYZus{}func\PYZus{}prime} \PY{o}{=} \PY{n}{sigmoid\PYZus{}prime}\PY{p}{,}
                           \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.001}\PY{p}{)}
        
        \PY{n}{MSE\PYZus{}boston\PYZus{}NN} \PY{o}{=} \PY{n}{NeuralNetwork}\PY{p}{(}\PY{n}{layers} \PY{o}{=} \PY{n}{torch}\PY{o}{.}\PY{n}{tensor}\PY{p}{(}\PY{p}{[}\PY{p}{[}\PY{n}{input\PYZus{}s}\PY{p}{,} \PY{n}{hidden\PYZus{}s}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{hidden\PYZus{}s}\PY{p}{,}
        \PY{n}{output\PYZus{}s}\PY{p}{]}\PY{p}{]}\PY{p}{)}\PY{p}{,}
                           \PY{n}{loss\PYZus{}func} \PY{o}{=} \PY{n}{square\PYZus{}error}\PY{p}{,}
                           \PY{n}{active\PYZus{}func} \PY{o}{=} \PY{n}{sigmoid}\PY{p}{,}
                           \PY{n}{active\PYZus{}func\PYZus{}prime} \PY{o}{=} \PY{n}{sigmoid\PYZus{}prime}\PY{p}{,}
                           \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.001}\PY{p}{)}
        
        
        \PY{n}{MAE\PYZus{}boston\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{MAE\PYZus{}boston\PYZus{}test\PYZus{}loss} \PY{o}{=} \PY{n}{run\PYZus{}nn}\PY{p}{(}\PY{n}{MAE\PYZus{}boston\PYZus{}NN}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,}
        \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{500}\PY{p}{)}
        \PY{n}{MSE\PYZus{}boston\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{MSE\PYZus{}boston\PYZus{}test\PYZus{}loss} \PY{o}{=} \PY{n}{run\PYZus{}nn}\PY{p}{(}\PY{n}{MSE\PYZus{}boston\PYZus{}NN}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,}
        \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{500}\PY{p}{)}
\end{Verbatim}

   \begin{Verbatim}[commandchars=\\\{\},fontsize=\scriptsize]
{\color{incolor}In [{\color{incolor}346}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{16}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
          
          \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{500}
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Neural Network with MAE Loss Function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MAE\PYZus{}boston\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MAE\PYZus{}boston\PYZus{}test\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epochs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Neural Network with MSE Loss Function}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MSE\PYZus{}boston\PYZus{}train\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{train\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{epochs}\PY{p}{)}\PY{p}{,} \PY{n}{MSE\PYZus{}boston\PYZus{}test\PYZus{}loss}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{test\PYZus{}loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Epochs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loss}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}346}]:} <matplotlib.legend.Legend at 0x7fedc1e527f0>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={1.0\linewidth}{0.9\paperheight}}{DL_Assignment_1_files/DL_Assignment_1_33_1.png}
    \end{center}
    
    The results show that the network training is much more unstable on the
boston dataset vs my self-created fake dataset. With a MAE loss
function, we see that the "pathway" to the local optima isn't as smooth
a descend as the trend lines on the fake dataset. That being said, upon
finding the local optima, the lines smooth out and there isn't any
identifiable jitter.\\

However, with a MSE loss function, the neural network appears to be
stuck at the wrong local optima and is unable to take any gradient
descent steps to decrease the loss any further.\\

This is probably because the boston dataset has a more complex
underlying function with 10+ features while my dataset only had 5
feature variables.

    \section{Summary}\label{summary}

While my neural network class displays a decreasing loss trend on my
fake dataset, it has a very unstable loss trend on the boston housing
dataset (even post-scaling). As stated above, this is probably because
the Boston dataset has a more complex underlying function vs the fake
dataset I created. My neural network is very simple - it lacks a bias
term which could help to map a displacement in the function, it lacks
regularization methods such as momentum and weight decay (which could
help to stabilize convergence to the optima and by extension, the
decrease in loss), and I only implemented one hidden layer in each
example.
\newpage
    \section{References}\label{references}

    Brilliant.org (2019). Feedforward Neural Networks. Retrieved October 14,
2019, from https://brilliant.org/wiki/feedforward-neural-networks/\\

Google Developers. (2019). Backpropagation Demo. Retrieved October 14,
2019, from
https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/.\\

Karpathy, A. (2016). Cs231n convolutional neural networks for visual
recognition. Neural networks, 1. Retrieved October 14, 2019, from
http://cs231n.github.io/neural-networks-1/.\\

Olah, C., Mordvintsev, A., \& Schubert, L. (2017). Feature
visualization. Distill, 2(11), e7.\\

Ruder, S. (2018, November 29). An overview of gradient descent
optimization algorithms. Retrieved October 14, 2019, from
http://ruder.io/optimizing-gradient-descent/index.html\#stochasticgradientdescent.\\

Scikit-learn. (2019). Boston House Prices Dataset. Retrieved October 19,
2019, from
https://scikit-learn.org/stable/datasets/index.html\#boston-house-prices-dataset.

\section{Appendix}

All code can be found here: \url{https://github.com/hueyning/DeepLearningTutorial/blob/master/DL_Assignment_1.ipynb}

    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
