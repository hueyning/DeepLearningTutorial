{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-Assignment-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hueyning/DeepLearningTutorial/blob/master/DL_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99tajFIugzJY",
        "colab_type": "text"
      },
      "source": [
        "To do:\n",
        "* clean up nn class\n",
        "* finish backprop concept breakdown\n",
        "* compare relu vs sigmoid? Compare learning rates?\n",
        "* Weight decay?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmEfqylTgk1h",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Assignment 1: Neural Network Fundamentals\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-ajeP7zzpkR",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, we will implement a neural network from scratch either in Numpy or in PyTorch but without using any of PyTorch’s implementations for layers, optimizers, loss functions, callbacks etc - all significant logic relating to the neural network should be written by the student. We are only allowed to use PyTorch for Numpy-like GPU-accelerated tensor manipulation, dataset-related data structures, and optionally gradient calculations (autograd).\n",
        "\n",
        "### Requirements:\n",
        "\n",
        "Implement a fully-connected (feed-forward) neural network from scratch in your library of choice. The NN must include at least dense layers, activations, and sigmoid/softmax in case of classification. You must also write your own optimizer and loss function (for example, stochastic gradient descent and binary cross-entropy for binary classification). You may use PyTorch’s built-in gradient calculator (autograd) or you may write one yourself.\n",
        "\n",
        "Finally, include runtime and results on a public dataset (MNIST? CIFAR10?).\n",
        "\n",
        "Please document your code and write a brief summary which includes any interesting technical details and your results.\n",
        "\n",
        "### Extensions:\n",
        "\n",
        "Implement one or more of the following, and include a comparison of the model’s performance with/without each component:\n",
        "\n",
        "* Manually calculate the gradients of each layer, and perform back propagation manually.\n",
        "* More than 1 activation function - sigmoid, tanh, relu etc.\n",
        "* More than 1 optimizer - SGD, Momentum, RMSProp, Adam etc.\n",
        "* Regularization - L2/weight decay, dropout, possibly augmentations if image data etc.\n",
        "\n",
        "\n",
        "### Submission:\n",
        "\n",
        "Please put all your code, results, and discussion in a jupyter notebook, and submit a pdf of the notebook for ease of grading. You may also make a secondary submission of the notebook (*.ipynb) or the code (*.py), but this is optional and might not be looked at."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJQwIVonwkK",
        "colab_type": "text"
      },
      "source": [
        "# Assignment Layout\n",
        "\n",
        "The assignment will consist of two main parts:\n",
        "\n",
        "1. Conceptual breakdown of the fundamentals of neural network architecture and the training process. This will allow me to grasp the fundamentals needed to code a neural network from scratch.\n",
        "\n",
        "2. Coding of the neural network using Pytorch.\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmHLpP2cePJv",
        "colab_type": "text"
      },
      "source": [
        "# Conceptual Breakdown\n",
        "\n",
        "The steps for training a neural network can be broken down as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asyemiIJzmlj",
        "colab_type": "text"
      },
      "source": [
        "## 1. Initialize the network parameters.\n",
        "\n",
        "### 1.1 Fixed Parameters\n",
        "\n",
        "The fixed parameters are the number of neurons in each layer, aka the layer size. These are usually defined by the user and determined as according to our dataset needs. \n",
        "\n",
        "#### 1.1.1 Input size and hidden layer size\n",
        "\n",
        "The number of neurons in the input layer and hidden layer(s) can be defined arbitrarily or according to common best practices. Increasing the number of neurons (and number of layers) can increase the model capacity, i.e. the space of representable functions, which allows the modelling of more complex relations, but also makes the model prone to overfitting (Kaparthy, 2019). It is a general rule of thumb that the number of learnable parameters should not exceed the number of data points. That being said, Kaparthy argues that neural networks that are overfitting can and should be adjusted using regularization methods vs reducing the neuron count (2019).\n",
        "\n",
        "Given the layer size(s) $s$, we can calculate the number of learnable parameters, $p$, from a fully-connected network with $N$ number of layers as follows:\n",
        "\n",
        "$p_{\\text{weights}} = \\sum_{i=0}^{N}{s_{i}\\cdot s_{i+1}}$\n",
        "\n",
        "$p_{\\text{bias}} = \\sum_{i=1}^{N}{s_i}$\n",
        "\n",
        "$p = p_{\\text{weights}} + p_{\\text{bias}}$\n",
        "\n",
        "In the equations above, $i=0$ denotes the input layer and $i=N$ denotes the output layer.\n",
        "\n",
        "#### 1.1.2 Output size\n",
        "\n",
        "In cases of binary classification or regression, the final output size should be one. In multilabel classification, the final output size should correspond to the number of classes.\n",
        "\n",
        "### 1.2 Learnable Parameters\n",
        "\n",
        "While fixed parameters are only initialized once when defining the network, learnable parameters are continuously updated throughout the training process to minimize training loss and adjust the model's predicted outputs to be closer to the actual output.\n",
        "\n",
        "The learnable parameters consist of the model weights and biases, and are usually randomly initialized.\n",
        "\n",
        "#### 1.2.1 Weights\n",
        "\n",
        "The weights determine the relationship between the neurons in a given layer to the neurons in the layer before and after it. The heavier the weight, the stronger the interneuron connection, and the stronger the implication that the neuron significantly affects our model's prediction ability. This is mostly relevant in regards to the input layer where the neurons may represent clear features of a given dataset. Neurons in the hidden layers are often less interpretable since they have undergone multiple transformations, though there have been relatively successful attempts at visualizing hidden layer features as shown in Olah, Mordvintsev, and Schubert (2017).\n",
        "\n",
        "#### 1.2.2 Bias\n",
        "\n",
        "The bias term allows us to adjust the displacement of the output functions of any given layer to achieve a better fit that reduces loss, i.e. the difference between predicted $\\hat{y}$ and actual $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ipy6nnwze-3",
        "colab_type": "text"
      },
      "source": [
        "## 2. Perform a feed-forward pass to compute the predicted output.\n",
        "\n",
        "According to Karpathy (2019), \"[t]he forward pass of a fully-connected layer corresponds to one matrix multiplication followed by a bias offset and an activation function\". The forward pass allows us to use the parameters that we have been training to predict an output based on our input. The steps are as follows:\n",
        "\n",
        "For each layer in the network:\n",
        "\n",
        "### 2.1 Multiply the layer inputs by their corresponding weights and add the bias offset.\n",
        "\n",
        "Given a layer with weights $\\vec{w}$, inputs $\\vec{x}$, and bias term $b$, the output (before activation) can be calculated as follows:\n",
        "\n",
        "$o = \\vec{w} \\cdot \\vec{x} + b$\n",
        "\n",
        "\n",
        "### 2.2 Apply an activation function.\n",
        "\n",
        "Since the output is linear, we need to apply an activation function to model non-linearity within our layer outputs. Given an activation function $g(x)$, our output can then be written as:\n",
        "\n",
        "$o = g(\\vec{w} \\cdot \\vec{x} + b)$\n",
        "\n",
        "Example activation functions include the sigmoid, softmax, rectified linear units (ReLU), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyEBGbncGXGa",
        "colab_type": "text"
      },
      "source": [
        "## 3. Compute the loss.\n",
        "\n",
        "The loss is defined as the difference between the predicted output $\\hat{y}$ and the actual output $y$ for an input $\\vec{x}$. The loss is calculated using the loss function, which can take on different forms as called for by the given problem.\n",
        "\n",
        "\n",
        "For regression problems, we typically use the mean squared error (MSE) as a loss function. For classification problems, we typically use cross-entropy loss (also called log loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfl5EOrROvkn",
        "colab_type": "text"
      },
      "source": [
        "## 4. Update parameters using gradient descent and backpropagation.\n",
        "\n",
        "Given a MSE loss function $L(X) = \\frac{1}{n}\\sum_{i=1}^{n}{(\\hat{y_i} - y_i)^2}$, where $X$ denotes a set of input-output pairs $X=\\{(\\vec{x_1},y_1),...,(\\vec{x_n},y_n)\\}$, $\\hat{y}$ denotes the predicted output, and ${y}$ denotes the actual output, we see that when $\\hat{y} = y$, $L(X) = 0$. As such, a natural objective is to minimize the loss function to achieve more accurate output. This can be done by adjusting the parameters that will affect the output, as shown in section 2.2. \n",
        "\n",
        "### 4.1 Minimizing loss and updating parameters using gradient descent.\n",
        "Since we are trying to minimize the loss, this is an optimization problem that can be solved using gradient descent. We typically use stochastic gradient descent (SGD) whereby a parameter update is performed for each training example $x_i$ and training label $y_i$ (Ruder, 2018). Each iteration of gradient descent would be carried out as follows:\n",
        "\n",
        "$\\theta_{t+1} = \\theta_t - \\alpha \\cdot \\nabla_\\theta L( \\theta; x^{(i)}; y^{(i)})$\n",
        "\n",
        "where $\\alpha$ represents the learning rate (usually user-defined and should follow industry best practices) and $\\nabla_\\theta L( \\theta; x^{(i)}; y^{(i)})$ represents the gradient of the loss function w.r.t the parameters.\n",
        "\n",
        "As seen from the update equation, each gradient descent step will update our parameters in the direction that decreases loss. If the loss term $(\\alpha \\cdot \\nabla_\\theta L( \\theta; x^{(i)}; y^{(i)})$ is positive, then the parameter values are decreased, i.e. we want to decrease the significance of this parameter since it is increasing loss. If the loss term is negative, then the parameter values are increased, i.e. we want to increase the significance of this parameter since it is decreasing loss. \n",
        "\n",
        "Through gradient descent, we iteratively update our parameters to achieve a local optima where loss is minimized.\n",
        "\n",
        "### 4.2 Calculating loss function gradient w.r.t. the parameters using backpropagation.\n",
        "\n",
        "The backpropagation algorithm uses the chain rule to calculate the gradient of the loss function w.r.t. to the parameters, i.e. the weights and biases. \n",
        "\n",
        "(Google Developers, 2019)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHLLuY1YebdZ",
        "colab_type": "text"
      },
      "source": [
        "# Coding the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-FiFE3agnR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_DHg1EtR8Na",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Class\n",
        "\n",
        "The neural network class consists of the following components:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSiH9H3t-tSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define neural network class\n",
        "\n",
        "class NeuralNetwork:\n",
        "  \n",
        "  def __init__(self, layers, loss_func, active_func, active_func_prime, alpha = 0.01):\n",
        "    \n",
        "    '''\n",
        "    Basic neural network class that can be trained on a given set of data using the self.train method.\n",
        "    \n",
        "    Inputs:\n",
        "    \n",
        "      layers (MAT)\n",
        "      \n",
        "        - Defines the architecture of the neural network.\n",
        "        - The array should contain sub-arrays that represent the network layers, so that \n",
        "          number of sub-arrays == number of layers in network (including input and output layers).\n",
        "          Ex: [[...],[...],[...]] would represent a network with 3 layers.\n",
        "        - The sub-arrays should each contain 2 numbers, the first representing the number of input neurons\n",
        "          and the second representing the number of output neurons.\n",
        "          Ex: [5,3] would represent a layer with 5 input neurons and 3 output neurons.\n",
        "          The following layer must accordingly have 3 input neurons, e.g. [3, x]\n",
        "        \n",
        "      loss_func (FUNC)\n",
        "      \n",
        "        - Defines the loss function to be used in the neural network.\n",
        "        \n",
        "      active_func (FUNC)\n",
        "      \n",
        "        - Defines the activation function to be used in the neural network.\n",
        "        - Only one type of activation function can be chosen, and this activation function\n",
        "          will be applied to each layer in the network, except the output layer.\n",
        "      \n",
        "      active_func_prime (FUNC)\n",
        "      \n",
        "        - The derivative of the chosen activation function.  \n",
        "          \n",
        "      alpha (FLOAT)\n",
        "      \n",
        "        - Defines the learning rate to be used in the optimization method (SGD).\n",
        "        - Default: 0.01\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    self.weight_dct = {} # empty dict to store layer weights\n",
        "    self.layer_output_dct = {} # empty dict to store layer outputs\n",
        "    self.delta_dct = {} # empty dict to store loss gradients\n",
        "    \n",
        "    for l in range(len(layers)):\n",
        "      # randomly initialize layer weights according to layer size\n",
        "      self.weight_dct[l] = torch.randn(layers[l,0], layers[l,1]) \n",
        "      \n",
        "    self.loss_func = loss_func # type of loss function\n",
        "    self.active_func = active_func # type of activation function\n",
        "    self.active_func_prime = active_func_prime # derivative of activation function\n",
        "    self.alpha = alpha # learning rate\n",
        "    \n",
        "    \n",
        "  def forward(self, layer_input):\n",
        "    \n",
        "    '''\n",
        "    *** Forward-pass algorithm ***\n",
        "    Multiplies the layer inputs by layer weights and applies the user-defined activation function\n",
        "    to every layer except the final output layer.\n",
        "    \n",
        "    Inputs:\n",
        "      \n",
        "      layer_input (MAT)\n",
        "        The layer inputs.\n",
        "        \n",
        "    Outputs:\n",
        "    \n",
        "      layer_output (MAT)\n",
        "        The output of the final layer.\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    layer_output = 0 # initialize output value as 0\n",
        "    \n",
        "    for i in range(len(self.weight_dct)): # loop through each layer in the network\n",
        "\n",
        "      layer_output = torch.matmul(layer_input, self.weight_dct[i]) # multiply the layer input by its weights\n",
        "      \n",
        "      if i != len(self.weight_dct) - 1: # apply activation function to all layers but the last\n",
        "        layer_output = self.active_func(layer_output) # activation function\n",
        "        \n",
        "      self.layer_output_dct[i] = layer_output # add layer output to the layer output dict\n",
        "      layer_input = layer_output # pass the output as the input to the next layer\n",
        "\n",
        "    return layer_output # return final output of last layer in the network\n",
        "  \n",
        "  \n",
        "  def backward(self, output, y_true):\n",
        "    \n",
        "    '''\n",
        "    *** Backpropagation algorithm ***\n",
        "    Loops through the network in reverse to calculate and sstore the \n",
        "    error derivative w.r.t. the total input of a node, dE/dx.\n",
        "    The dE/dx's are stored in delta_dct.\n",
        "    \n",
        "    Inputs:\n",
        "      \n",
        "      output (MAT)\n",
        "        The predicted y values, i.e. final layer outputs.\n",
        "        \n",
        "      y_true (MAT)\n",
        "        The true y values.\n",
        "\n",
        "    '''\n",
        "    \n",
        "    err = self.loss_func(output, y_true) # output error, dE/dy\n",
        "    delta = err * self.active_func_prime(output) # derivative of error w.r.t input, dE/dx = dE/dy * dy/dx, \n",
        "                                                # where dy/dx is the derivative of the activation function w.r.t. the output.\n",
        "    \n",
        "    for i in reversed(range(1, len(self.weight_dct))): # loop through the layers in reverse to backprop\n",
        "      \n",
        "      err = torch.matmul(delta, torch.t(self.weight_dct[i])) # dE/dy for the layer\n",
        "      delta = err * self.active_func_prime(self.layer_output_dct[i]) # dE/dx for the layer\n",
        "    \n",
        "      self.delta_dct[i] = delta # save the deltas for calculating the loss gradient w.r.t. params, dE/dw\n",
        "        \n",
        "  \n",
        "  def optimize(self, layer_input):\n",
        "    \n",
        "    '''\n",
        "    *** Optimization step: Gradient Descent ***\n",
        "    Loops through the network and calculates the the error derivative w.r.t. the weights coming into\n",
        "    the nodes of each layer, dE/dw. Ths loss gradient is then used to update the weights by \n",
        "    multiplying it with a learning_rate factor.\n",
        "    \n",
        "    Inputs:\n",
        "      \n",
        "      layer_input (MAT)\n",
        "        The initial input of the first layer, aka the \"X\" data.\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    # loop through all layers except the output layer which doesn't have params to optimize\n",
        "    for i in range(len(self.weight_dct)-1): \n",
        "      \n",
        "      loss_gradient = torch.matmul(torch.t(layer_input), self.delta_dct[i+1]) # calculate dE/dw\n",
        "      self.weight_dct[i] -= self.alpha * loss_gradient # update params using α * dE/dw\n",
        "      \n",
        "      # the input for the next layer, i + 1, will be the output from the layer before it, i\n",
        "      layer_input = self.layer_output_dct[i] \n",
        "      \n",
        "      \n",
        "  def train(self, layer_input, y_true):\n",
        "    \n",
        "    '''\n",
        "    *** Train the Network ***\n",
        "    Trains the neural network through one iteration of:\n",
        "    1) Calculating the predicted y's using a forward pass on the x data,\n",
        "    2) Using backprop to find the loss gradients,\n",
        "    3) Optimizing weights using the loss gradients.\n",
        "    \n",
        "    Inputs:\n",
        "      \n",
        "      layer_input (MAT)\n",
        "        The initial input of the first layer, aka the \"X\" data.\n",
        "        \n",
        "      y_true (MAT)\n",
        "        The true y values.\n",
        "        \n",
        "    '''\n",
        "    \n",
        "    # forward pass\n",
        "    y_pred = self.forward(layer_input)\n",
        "    # backward pass\n",
        "    self.backward(y_pred, y_true)\n",
        "    # optimize\n",
        "    self.optimize(layer_input)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG-xbKxIv35p",
        "colab_type": "text"
      },
      "source": [
        "## Activation Functions and their Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07OwQ8ZrvL-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(s): # for binary classification\n",
        "  return 1/(1 + torch.exp(-s)) \n",
        "  \n",
        "def sigmoid_prime(s):\n",
        "  return s * (1-s)\n",
        "  \n",
        "def relu(s):\n",
        "  return s * (s > 0).float()\n",
        "\n",
        "def relu_prime(s):\n",
        "  return 1. * (s > 0).float()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR-6p-FCxlX0",
        "colab_type": "text"
      },
      "source": [
        "## Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzFZ2qsJxl47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def absolute_error(y_pred, y_true):\n",
        "  return abs(y_pred - y_true)\n",
        "\n",
        "\n",
        "def square_error(y_pred, y_true):\n",
        "  return (y_pred - y_true)**2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9em8VfXM0jdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_nn(NN, X_train, y_train, X_test, y_test, epochs = 1000, disp = False):\n",
        "  \n",
        "  # keep track of train and test loss\n",
        "  running_train_loss = []\n",
        "  running_test_loss = []\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    # train network\n",
        "    NN.train(X_train, y_train)\n",
        "    train_loss = torch.mean(square_error(NN.forward(X_train), y_train))\n",
        "    running_train_loss.append(train_loss)\n",
        "\n",
        "    # test network\n",
        "    test_loss = torch.mean(square_error(NN.forward(X_test), y_test))\n",
        "    running_test_loss.append(test_loss)\n",
        "\n",
        "    if i % 100 == 0 and disp == True:\n",
        "      print(f\"Epoch {i}\")\n",
        "      print (\"Train Loss: \" + str(train_loss)) \n",
        "      print (\"Test Loss: \" + str(test_loss)) \n",
        "      \n",
        "  return running_train_loss, running_test_loss\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fYKrQvqR57M",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Test: Fake Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J34Bo77uSWqy",
        "colab_type": "text"
      },
      "source": [
        "### Create the Fake Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcQPPkdn6Xki",
        "colab_type": "code",
        "outputId": "88cae336-a277-47bd-c209-052446be4a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(2)\n",
        "\n",
        "def f(x):\n",
        "  return torch.mean(x, dim=1)**2 + torch.mean(x, dim=1) + np.random.normal(0, 0.05)\n",
        "\n",
        "# train set\n",
        "X_train = torch.randn(100, 5) \n",
        "y_train = f(X_train).reshape(-1, 1)\n",
        "\n",
        "# test set\n",
        "X_test = torch.randn(30, 5) \n",
        "y_test = f(X_test).reshape(-1, 1)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 5]) torch.Size([30, 5]) torch.Size([100, 1]) torch.Size([30, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP1ptivlSYcG",
        "colab_type": "text"
      },
      "source": [
        "### Run the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJZt_csB0fcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define layer sizes\n",
        "input_s = X_train.size()[1]\n",
        "hidden_s = 10\n",
        "output_s = 1\n",
        "\n",
        "# initialize networks\n",
        "MAE_NN = NeuralNetwork(layers = torch.tensor([[input_s, hidden_s],[hidden_s, output_s]]),\n",
        "                   loss_func = absolute_error,\n",
        "                   active_func = relu,\n",
        "                   active_func_prime = relu_prime,\n",
        "                   alpha = 0.001)\n",
        "\n",
        "MSE_NN = NeuralNetwork(layers = torch.tensor([[input_s, hidden_s],[hidden_s, output_s]]),\n",
        "                   loss_func = square_error,\n",
        "                   active_func = relu,\n",
        "                   active_func_prime = relu_prime,\n",
        "                   alpha = 0.001)\n",
        "\n",
        "\n",
        "MAE_train_loss, MAE_test_loss = run_nn(MAE_NN, X_train, y_train, X_test, y_test, epochs = 1000)\n",
        "MSE_train_loss, MSE_test_loss = run_nn(MSE_NN, X_train, y_train, X_test, y_test, epochs = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6UMDZm7lqBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "1611df71-036e-4f49-9ae8-acebf583eb81"
      },
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "epochs = 1000\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Neural Network with MAE Loss Function')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MAE_train_loss, label='train_loss')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MAE_test_loss, label='test_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Neural Network with MSE Loss Function')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MSE_train_loss, label='train_loss')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MSE_test_loss, label='test_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f86acf66dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAEcCAYAAAD5txMHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQgghhBgDUmgLIYQQQggxBv4/cVLksCqe2PMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtXc2a5PNeL_",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network Test: Public Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PayXYaNvSb9F",
        "colab_type": "text"
      },
      "source": [
        "### Import Boston Housing Prices Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz6gos7kNdv-",
        "colab_type": "code",
        "outputId": "16738896-d02b-4c10-9075-02821bf0c2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "# load data\n",
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "\n",
        "boston = load_boston()\n",
        "\n",
        "boston_data_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "print(boston.data.shape)\n",
        "boston_data_df.describe().round()"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "      <td>506.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>408.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>666.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>89.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>711.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM     ZN  INDUS   CHAS    NOX  ...    RAD    TAX  PTRATIO      B  LSTAT\n",
              "count  506.0  506.0  506.0  506.0  506.0  ...  506.0  506.0    506.0  506.0  506.0\n",
              "mean     4.0   11.0   11.0    0.0    1.0  ...   10.0  408.0     18.0  357.0   13.0\n",
              "std      9.0   23.0    7.0    0.0    0.0  ...    9.0  169.0      2.0   91.0    7.0\n",
              "min      0.0    0.0    0.0    0.0    0.0  ...    1.0  187.0     13.0    0.0    2.0\n",
              "25%      0.0    0.0    5.0    0.0    0.0  ...    4.0  279.0     17.0  375.0    7.0\n",
              "50%      0.0    0.0   10.0    0.0    1.0  ...    5.0  330.0     19.0  391.0   11.0\n",
              "75%      4.0   12.0   18.0    0.0    1.0  ...   24.0  666.0     20.0  396.0   17.0\n",
              "max     89.0  100.0   28.0    1.0    1.0  ...   24.0  711.0     22.0  397.0   38.0\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U8x5HSttIFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "f62e5269-e8b9-4713-e8b7-ebf22098557a"
      },
      "source": [
        "boston_target_df = pd.DataFrame(boston.target, columns=['MEDIAN VALUE'])\n",
        "print(boston.target.shape)\n",
        "boston_target_df.describe().round()"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MEDIAN VALUE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       MEDIAN VALUE\n",
              "count         506.0\n",
              "mean           23.0\n",
              "std             9.0\n",
              "min             5.0\n",
              "25%            17.0\n",
              "50%            21.0\n",
              "75%            25.0\n",
              "max            50.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_Xc62ZXSkE6",
        "colab_type": "text"
      },
      "source": [
        "### Transform and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c2wvjggPkCj",
        "colab_type": "code",
        "outputId": "a13a597d-a0c7-4dc2-f076-1e8055613785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# scale data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(boston.data)\n",
        "y = scaler.fit_transform(boston.target.reshape(-1, 1))\n",
        "\n",
        "# split data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(339, 13) (167, 13) (339, 1) (167, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53vfjo8gObIR",
        "colab_type": "code",
        "outputId": "5cb2dcce-3f94-4cde-93b5-82506ac19fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# transform data into tensor with dtype = Float\n",
        "def transform_to_tensor(data):\n",
        "  return torch.tensor(data, dtype=torch.float)\n",
        "\n",
        "X_train = transform_to_tensor(X_train)\n",
        "X_test = transform_to_tensor(X_test)\n",
        "y_train = transform_to_tensor(y_train)\n",
        "y_test = transform_to_tensor(y_test)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([339, 13]) torch.Size([167, 13]) torch.Size([339, 1]) torch.Size([167, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMzIBuRPSrxW",
        "colab_type": "text"
      },
      "source": [
        "### Run the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xldbKVAQOIwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define layer sizes\n",
        "input_s = X_train.shape[1]\n",
        "hidden_s = 50\n",
        "output_s = 1\n",
        "\n",
        "# initialize networks\n",
        "MAE_boston_NN = NeuralNetwork(layers = torch.tensor([[input_s, hidden_s],[hidden_s, output_s]]),\n",
        "                   loss_func = absolute_error,\n",
        "                   active_func = sigmoid,\n",
        "                   active_func_prime = sigmoid_prime,\n",
        "                   alpha = 0.001)\n",
        "\n",
        "MSE_boston_NN = NeuralNetwork(layers = torch.tensor([[input_s, hidden_s],[hidden_s, output_s]]),\n",
        "                   loss_func = square_error,\n",
        "                   active_func = sigmoid,\n",
        "                   active_func_prime = sigmoid_prime,\n",
        "                   alpha = 0.001)\n",
        "\n",
        "\n",
        "MAE_boston_train_loss, MAE_boston_test_loss = run_nn(MAE_boston_NN, X_train, y_train, X_test, y_test, epochs = 1000)\n",
        "MSE_boston_train_loss, MSE_boston_test_loss = run_nn(MSE_boston_NN, X_train, y_train, X_test, y_test, epochs = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sLDtIttmMBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "dd9a3516-fad2-49e8-f9d1-7b13e49a580c"
      },
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "epochs = 1000\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Neural Network with MAE Loss Function')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MAE_boston_train_loss, label='train_loss')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MAE_boston_test_loss, label='test_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Neural Network with MSE Loss Function')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MSE_boston_train_loss, label='train_loss')\n",
        "plt.plot(np.linspace(0,epochs,epochs), MSE_boston_test_loss, label='test_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f86ac0ac668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 354
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAEcCAYAAAB+hvoBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6MK0unN4d8Z",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df_yhUkIjVcj",
        "colab_type": "text"
      },
      "source": [
        "Brilliant.org (2019). Feedforward Neural Networks. Retrieved October 14, 2019, from https://brilliant.org/wiki/feedforward-neural-networks/\n",
        "\n",
        "Google Developers. (2019). Backpropagation Demo. Retrieved October 14, 2019, from https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/.\n",
        "\n",
        "Karpathy, A. (2016). Cs231n convolutional neural networks for visual recognition. Neural networks, 1. Retrieved October 14, 2019, from http://cs231n.github.io/neural-networks-1/.\n",
        "\n",
        "Olah, C., Mordvintsev, A., & Schubert, L. (2017). Feature visualization. Distill, 2(11), e7.\n",
        "\n",
        "Ruder, S. (2018, November 29). An overview of gradient descent optimization algorithms. Retrieved October 14, 2019, from http://ruder.io/optimizing-gradient-descent/index.html#stochasticgradientdescent."
      ]
    }
  ]
}